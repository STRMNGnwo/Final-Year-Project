{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/STRMNGnwo/Final-Year-Project/blob/trained-fulldataset-4epochs/FYP_UNETmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM0-aLwOs3eh",
        "outputId": "cd64e849-4f25-4a59-9837-cfc87a5cec0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "#files.upload()\n",
        "\n",
        "#g drive file path to total dataset /content/drive/MyDrive/FYP-Aortic_Dissection_Segmentation/datasets\n",
        "#g drive file path to split dataset /content/drive/MyDrive/FYP-Aortic_Dissection_Segmentation/Split_Patients\n",
        "#g drive file path to split dataset /content/drive/MyDrive/FYP-Aortic_Dissection_Segmentation/\n",
        "drive.mount(\"/content/drive/\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdCHmab5stpj",
        "outputId": "a2a10845-3e87-4247-d750-7a751f9a783e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ],
      "source": [
        "#importing the required modules to create the U-Net model\n",
        "import torch, torchvision\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d #The convolutional layer used in the U-Net architecture\n",
        "from torch.nn import ReLU #activation function\n",
        "from torch.nn import BatchNorm1d, BatchNorm2d\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import functional as f #to make the fully connected layer\n",
        "from torch.nn import ConvTranspose2d\n",
        "from torch.nn import MaxPool2d #max pooling layer that is implemented after Conv2d layers\n",
        "from torchvision import transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, '/content/drive/MyDrive/FYP-Aortic_Dissection_Segmentation/')\n",
        "\n",
        "#from CustomDataset import SegmentationCTADataset\n",
        "from CustomDataset import CTADataset\n",
        "#from split_patients import remove_DS_Store, split_patients, copy_collate_datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  torch.cuda.get_device_name(0)\n",
        "  print(\"GPU\")\n",
        "\n",
        "else:\n",
        "  device=\"cpu\"\n",
        "  print(\"CPU\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUu3SuR5stpz"
      },
      "source": [
        "Importing the datasst data, which has been split into train,test and val sets by unzipping the prepared dataset file that is found in my google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFXz_lKvstpz"
      },
      "outputs": [],
      "source": [
        "\n",
        "!unzip /content/drive/MyDrive/FYP-Aortic_Dissection_Segmentation/Prepared_Dataset.zip\n",
        "\n",
        "#unzip /content/drive/MyDrive/FYP-Aortic_Dissection_Segmentation/SampleTrain.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52R9wpR6stpp"
      },
      "source": [
        "Sliding Window CNNs involve dividing an input image into \"patches\" of pixels, passing each pixel into a CNN, and assigning a class label to the pixel. Their main benefit is that they can localize, and they can also result in more training data being available as a result of the patches being made. However they are very slow and computationally expensive.\n",
        "\n",
        "Localization -> assigning a class label to a region of pixels on a pixel-by-pixel basis.\n",
        "\n",
        "Trade-off between localization accuracy and the context available to the CNN-> exists due to varying patch sizes. Large Patch sizes allow for greater context, but lower localization accuracy and vice-versa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-fubXaSstpr"
      },
      "source": [
        "The U-NET Architecture:\n",
        "\n",
        "Consists of a contracting path that identifies context (descending/encoding) and a symmetrical expanding path that enables precise localization\n",
        "of contours. U-NET is popular for medical image segmentation and is proven to be better than sliding window CNNs.\n",
        "\n",
        "The Descending section:\n",
        "\n",
        "The descending section of the architecture consists of convolutional layers that are followed by max-pooling layers . \n",
        "This pattern (Conv,Conv,Max-Pool) repeats. \n",
        "The input image is down-sampled (image size reduces but the number of channels increases).\n",
        "After convolutions ->the number of channels seems to increase.\n",
        "After max-pooling -> the image size decreases.\n",
        "\n",
        "---------------------------\n",
        "The Ascending section:\n",
        "\n",
        "Consists of an expanding path, made up of convolutional layers and transposed convolutional layers(that upsample, ie increasing image size).\n",
        "The Conv. layers in this section seem to reduce the number of channels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9-LhSgmstpt"
      },
      "source": [
        "Notes from paper (3D UNET was used for segmentation): https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7817629/\n",
        "\n",
        "The down-sampling path had a filter size of 3 × 3 × 32 and stride 2 in each convolution layer. \n",
        "\n",
        "All convolution layers were processed with batch normalization, Rectified Linear Units, and same-padding. T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MiJ5SEZCstpt"
      },
      "outputs": [],
      "source": [
        "#Building block of both Encoder section and Decoder section.\n",
        "#At a high level: Encoder= Block +downsampling (max_pooling), Decoder= upsampling+ skip connection concatenation + Block\n",
        "# Block -> Double Convolutional layers, with Batch Normalisation and ReLU activation functions between them.\n",
        "class Block(Module):\n",
        "\n",
        "    def __init__(self, in_channels,out_channels):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.conv=Sequential(\n",
        "            #Conv1\n",
        "            #in_channels,out_channels,filter_size(kernel),stride,padding(same padding=1), bias\n",
        "            Conv2d(in_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False), # bias is false because batch normalisation is used in the next step and it cancels out bias\n",
        "            #NOTE: Would I need BatchNorm1D or BatchNorm2D?\n",
        "            \n",
        "            BatchNorm2d(out_channels),\n",
        "            ReLU(inplace=True),\n",
        "\n",
        "            #Conv2\n",
        "            Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False), #bias=False because batch normalisation is used in the next step and it cancels out bias\n",
        "            #NOTE: Would I need BatchNorm1D or BatchNorm2D?\n",
        "            \n",
        "            BatchNorm2d(out_channels),\n",
        "            ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8TQ6Lemastpv"
      },
      "outputs": [],
      "source": [
        "#the descending section made of conv.layers and max-pool layers.\n",
        "#The Encoder consists of multiple \"blocks\"  which consist of down-sampling and convolutional layers. \n",
        "#The Encoder reduces the spatial dimension and obtains information about the mask area/region of interest.\n",
        "class Encoder(Module): \n",
        "\n",
        "    def  __init__(self,encoding_channels=(1,64,128,256,512)): #the channel values should probably be modified based on the paper.. 3 assumes rgb but images I have are grey scale\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.channels=encoding_channels\n",
        "        self.encoding_blocks=torch.nn.ModuleList()\n",
        "\n",
        "        for i in range(0,len(self.channels)-1):\n",
        "            in_channel=self.channels[i]\n",
        "            out_channel=self.channels[i+1]\n",
        "            self.encoding_blocks.append(Block(in_channel,out_channel))\n",
        "\n",
        "        self.pool= MaxPool2d(kernel_size=2,stride=2) #reduces spatial dimensions by a factor of 2 each time it is called\n",
        "\n",
        "    \n",
        "    def forward(self,x):\n",
        "        #intermediary results between blocks are stored here\n",
        "        block_outputs=[]\n",
        "\n",
        "        for block in self.encoding_blocks:\n",
        "             \n",
        "            #print(\"Data before pooling and before convolutions\",x.shape)\n",
        "            x=block(x) # the block's forward method is implicitly called.\n",
        "\n",
        "            #print(\"Data before pooling and after convolutions\",x.shape)\n",
        "\n",
        "            #adding the block output to the list\n",
        "            block_outputs.append(x) \n",
        "\n",
        "            #sending the output of the block to the max pooling layer\n",
        "            x=self.pool(x)\n",
        "            #print(\"Data after pooling\",x.shape)\n",
        "\n",
        "    #return the final form of the data and the intermediary results (skip-connections used in the Decoder section, in the U-NET architecture paper)        \n",
        "        return [x,block_outputs] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tCKt9ZaPstpw"
      },
      "outputs": [],
      "source": [
        "#The Decoder class has Decoder blocks to take in input data and skip connections, perform upsampling, concatenation of skip connection to data and Conv2D.\n",
        "#The Decoder upsamples the localized information and provides context.\n",
        "class Decoder(Module):\n",
        "    \n",
        "    def __init__(self,decoding_channels=(512,256,128,64,2)): #2 is the final one because of 2 classes-> TL and FL\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.channels=decoding_channels\n",
        "        self.decoding_blocks=torch.nn.ModuleList()\n",
        "        \n",
        "        #upsampling going to use transpose convolutional layers. Can also use bilinear + convolution\n",
        "        self.upconvolutions=torch.nn.ModuleList()\n",
        "\n",
        "        #making the up-sampling layers and the decoding blocks\n",
        "        for i in range(0,len(decoding_channels)-1):\n",
        "            in_channel=self.channels[i]\n",
        "            out_channel=self.channels[i+1]\n",
        "            self.decoding_blocks.append(Block(in_channel,out_channel))\n",
        "\n",
        "            #NOTE due to the skip connections having to be added, would in_channel(first param below)  have to be *2\n",
        "            self.upconvolutions.append(ConvTranspose2d(self.channels[i],self.channels[i+1],kernel_size=2,stride=2))\n",
        "\n",
        "        \n",
        "    def forward(self,x,encoder_intermediary_outputs):#encoder_intermediary_outputs are the list of skip connections from the encoder.\n",
        "        \n",
        "        #print(\"\\n--------------Decoder------------------------\")\n",
        "        #print(\"Data in decoder\")\n",
        "\n",
        "        # for skipconnection in encoder_intermediary_outputs:\n",
        "        #     print(\"Shape of skip connection: \",skipconnection.shape)\n",
        "        \n",
        "        for i in range (len(self.upconvolutions)):\n",
        "\n",
        "            #print(\"Data shape before upsampling\",x.shape)\n",
        "\n",
        "            #using a transpose convolution to upsample the data (should )\n",
        "            x=self.upconvolutions[i](x)\n",
        "\n",
        "            #print(\"Data shape after upsampling\",x.shape)\n",
        "            \n",
        "            #concatenating an intermediary output from encoder section to the data\n",
        "            cropped_encoder_output=self.crop(encoder_intermediary_outputs[i],x)\n",
        "            x=torch.cat([x,cropped_encoder_output],dim=1)\n",
        "\n",
        "            #print(\"Data shape after concatenation with skip connection\",x.shape)\n",
        "\n",
        "            #sending the concatenated upsampled data through a decoding block\n",
        "            x= self.decoding_blocks[i](x)\n",
        "            #print(\"Data shape after upsampling, concatenation and convolution\",x.shape)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def crop(self, encoding_intermediary_output,x):\n",
        "        \n",
        "        #(_,_,H,W)=x.shape\n",
        "        (_,_,H,W)=x.shape\n",
        "        cropped_intermediary_output=torchvision.transforms.CenterCrop([H, W])(encoding_intermediary_output)\n",
        "\n",
        "        return cropped_intermediary_output\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "\n",
        "            \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yUsHvNxb-Zf5"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(Module):\n",
        "\n",
        "  def __init__(self, in_channels=None, out_channels=None):\n",
        "\n",
        "    super().__init__()\n",
        "    self.in_channels=in_channels\n",
        "    self.out_channels=out_channels\n",
        "\n",
        "    #bottleneck_block=Block(in_channels=encoder_intermediaries[::-1],out_channels=(encoder_intermediaries[::-1]*2))\n",
        "    self.block=Block(self.in_channels,self.out_channels)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zeWV-KJBstpx"
      },
      "outputs": [],
      "source": [
        "#Creating the U-NET class\n",
        "\n",
        "#U-NET architecture:\n",
        "\n",
        "\"\"\" \n",
        "Consists of a contracting path that identifies context (descending/encoding) and a symmetrical expanding path that enables precise localization\n",
        "of contours. U-NET is popular for medical image segmentation and is proven to be better than sliding window CNNs.\n",
        "\n",
        "Localization -> assigning a class label to a region of pixels on a pixel-by-pixel basis.\n",
        "\"\"\"\n",
        "\n",
        "class UNet(Module):\n",
        "\n",
        "    def __init__(self,encoding_channels=(1,64,128),decoding_channels=(256,128,64),seg_classes=3, retainDim=True, outSize=(128, 128)): \n",
        "        \n",
        "        #seg_classes is the number of classes that a pixel can belong to (2 being- TL and FL)\n",
        "        #seg_classes is also the number of channels expected by the final conv layer which generates the map.\n",
        "\n",
        "        #retainDim signifies if the original output dimension should be maintained or not when producing the map.\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        #Encoder and Decoder are classes. Encoder is the descending section and the Decoder is the ascending of \"U\"\n",
        "        self.encoder=Encoder(encoding_channels)\n",
        "        self.bottleneck_block= Bottleneck(encoding_channels[-1],(encoding_channels[-1]*2) )\n",
        "        self.decoder=Decoder(decoding_channels)\n",
        "\n",
        "        self.retainDim=retainDim\n",
        "        self.seg_classes=seg_classes\n",
        "        self.outSize=outSize\n",
        "\n",
        "        #defining the last single convolutional layer, which would output the segmentation map\n",
        "        #in_channel,out_channel,kernel_size\n",
        "        self.head=Conv2d(decoding_channels[-1],seg_classes,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #data's entry point into the model\n",
        "\n",
        "        #get intermediary output from encoder, as calling it implicity calls its forward method\n",
        "        encoder_results=self.encoder(x)\n",
        "        #obtain the skip connections\n",
        "        encoder_intermediaries=encoder_results[1]\n",
        "        #obtain the image that needs to be sent into the bottleneck block (\"between the Descending and Ascending sections\")\n",
        "        final_data_from_encoder=encoder_results[0]\n",
        "\n",
        "\n",
        "        #print(\"Encoder output shape:\",final_data_from_encoder.shape)\n",
        "\n",
        "        # the \"bottleneck\" layer-> layer between encoder and decoder, which has a double conv2d.\n",
        "\n",
        "        #passing in the final image output from the encoder into the bottleneck block (does 2 Conv2D convolutions)\n",
        "        bottleneck_output=self.bottleneck_block(final_data_from_encoder)\n",
        "\n",
        "        #passing in the encoder output in reverse(latest output to oldest output) as the data to its forward function\n",
        "        #and also passing in the encoder outputs to decoder\n",
        "        \n",
        "        #decoder_output=self.decoder(encoder_intermediaries[::-1][0],encoder_intermediaries[::-1][1:])\n",
        "\n",
        "\n",
        "        #print(\"Bottleneck block output shape:\",bottleneck_output.shape)\n",
        "\n",
        "        decoder_output=self.decoder(bottleneck_output,encoder_intermediaries[::-1])\n",
        "\n",
        "        map = self.head(decoder_output)\n",
        "\t\t\n",
        "        if self.retainDim:\n",
        "            map = torch.nn.functional.interpolate(map, self.outSize)\n",
        "\t\t\n",
        "        #print(\"The type of the model output is :\",type(map))\n",
        "        #print(\"The shape of the segmentation map is: \",map.shape)\n",
        "        \n",
        "        # return the segmentation map\n",
        "        return map\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5y4n_Lvdstpy"
      },
      "outputs": [],
      "source": [
        "def visualiser(image):\n",
        "\n",
        "    print(type(image))\n",
        "    if(type(image)==torch.Tensor):\n",
        "        print(\"tensor\")\n",
        "        transform=transforms.ToPILImage()\n",
        "        display=transform(image)\n",
        "        display.show()  \n",
        "\n",
        "    elif(type(image)==Image.Image):\n",
        "        print(\"image\")\n",
        "        image.show()\n",
        "\n",
        "from numpy import ndarray\n",
        "def visualiser_sample(image):\n",
        "  print(type(image))\n",
        "\n",
        "  if(type(image)==torch.Tensor):\n",
        "    print(\"Image is in a tensor format\")\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    #plt.imshow(image)\n",
        "    #plt.imshow((image* 255).astype(np.uint8))\n",
        "    plt.show()\n",
        "\n",
        "  if(type(image)==np.ndarray):\n",
        "    print(\"Image is a numpy array\")\n",
        "    image=torch.from_numpy(image)\n",
        "    plt.imshow(image)\n",
        "    plt.imshow((image* 255).astype(np.uint8))\n",
        "    plt.show()\n",
        "\n",
        "def visualiser_colab(image):\n",
        "  print(type(image))\n",
        "  print(\"Image shape in visualiser_colab:\",image.shape)\n",
        "\n",
        "  if(type(image)==torch.Tensor):\n",
        "    print(\"Image is in a tensor format\")\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "  if(type(image)==np.ndarray):\n",
        "    print(\"Image is a numpy array\")\n",
        "    image=torch.from_numpy(image)\n",
        "    #plt.imshow(image.permute(1, 2, 0))\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XMBjGm_rlq5B"
      },
      "outputs": [],
      "source": [
        "# from matplotlib import image\n",
        "# from matplotlib import pyplot\n",
        "\n",
        "# images=image.imread(\"/content/Prepared_Dataset/train/images/patient1-slice150.jpg\")\n",
        "# mask=image.imread(\"/content/Prepared_Dataset/train/masks/patient1-mask-slice150.jpg\")\n",
        "\n",
        "# pyplot.imshow(images)\n",
        "# pyplot.show()\n",
        "# pyplot.imshow(mask)\n",
        "# pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "5EINbT3kstp0",
        "outputId": "6b063426-b1e9-4ba3-8119-fa1f65713454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128, 128])\n",
            "(1, 128, 128)\n",
            "16384\n",
            "Length of sample dataset:  24257\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "train_path=\"/content/Prepared_Dataset/train\"\n",
        "val_path=\"/content/Prepared_Dataset/val\"\n",
        "test_path=\"/content/Prepared_Dataset/test\"\n",
        "\n",
        "sample_path=\"/content/SampleTrain\"\n",
        "\n",
        "#specifying transforms-> increasing contrast in the image and converting it to a Tensor\n",
        "train_transforms=transforms.Compose([transforms.Resize((128,128)),transforms.ToTensor()])\n",
        "val_transforms=transforms.Compose([transforms.ToTensor()])\n",
        "test_transforms=transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "#Setting up Custom Datasets and converting appropriate images to Tensors.\n",
        "\n",
        "train_dataset= CTADataset(os.path.join(train_path,\"images\"),os.path.join(train_path,\"masks\"),transform=train_transforms)\n",
        "val_dataset= CTADataset(os.path.join(val_path,\"images\"),os.path.join(val_path,\"masks\"),transform=val_transforms)\n",
        "test_dataset=CTADataset(os.path.join(test_path,\"images\"),os.path.join(test_path,\"masks\"),transform=test_transforms)\n",
        "\n",
        "#sample_dataset=CTADataset(os.path.join(sample_path,\"images\"),os.path.join(sample_path,\"masks\"),transform=train_transforms)\n",
        "\n",
        "#getting a sample image and mask from an arbitrary patient and displaying it.\n",
        "# target_map is the semantically segmented ground truth to be used in loss func\n",
        "train_sampleimage,train_samplemask,imagePath,maskPath,target_map=train_dataset.__getitem__(980)\n",
        "\n",
        "print(train_sampleimage.shape)\n",
        "# image_np= np.asarray(train_sampleimage)\n",
        "\n",
        "# print(image_np.size)\n",
        "print(target_map.shape)\n",
        "print(target_map.size)\n",
        "\n",
        "\n",
        "print(\"Length of sample dataset: \",train_dataset.__len__())\n",
        "# visualiser_sample(train_sampleimage)\n",
        "# visualiser_sample(train_samplemask)\n",
        "\n",
        "pyplot.imshow(train_samplemask.permute(1,2,0))\n",
        "pyplot.show()\n",
        "\n",
        "#for pyplot to show image, it must be in format: width,height. target map-> channel, width, height\n",
        "pyplot.imshow(np.squeeze(target_map)) #squeeze removes the channel dimension as its just 1\n",
        "\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLvJN99Qstp1"
      },
      "source": [
        "Creation of DataLoaders for the train, test and val datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7VKVlorstp1",
        "outputId": "0b75ecf3-27da-4590-f449-cff74f383cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "#making dataloaders for the train, test and val sets.\n",
        "\n",
        "train_loader= DataLoader(train_dataset,batch_size=16,shuffle=False,drop_last=True)\n",
        "\n",
        "print(train_loader.drop_last)\n",
        "# val_loader= DataLoader(val_dataset,batch_size=32,shuffle=False)\n",
        "# test_loader= DataLoader(test_dataset,batch_size=32,shuffle=False)\n",
        "\n",
        "# print(sample_dataset.__len__())\n",
        "\n",
        "#sample_loader=DataLoader(sample_dataset,batch_size=16,shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARxKoJCgstp2"
      },
      "source": [
        "Instantiating the UNET implementation model\n",
        "\n",
        "Encoder:\n",
        "Down-sample -> Max-pooling to reduce the size of the image.\n",
        "Conv2D-> To increase the number of channels.\n",
        "\n",
        "Decoder: \n",
        "Up-Sample -> To increase the image size\n",
        "Conv2D-> To decrease the number of channles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDrfN2pJ0eb5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi3YSs3Ostp2",
        "outputId": "14c9e110-3d10-4fdb-b9f4-4b534db7fcc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The device being used is:  cuda\n",
            "Encoder channels:  (3, 64, 128, 256, 512)\n",
            "Decoder Channels:  (1024, 512, 256, 128, 64)\n"
          ]
        }
      ],
      "source": [
        "#Instantiate the Block, Encoder,Decoder and UNET classes. Pass data into the UNET Class (model's data entrypoint)\n",
        "print(\"The device being used is: \",device)\n",
        "\n",
        "seg_map_height=128\n",
        "seg_map_width=128\n",
        "\n",
        "#encoding_channels=(3,64,128),decoding_channels=(256,128,64,2)\n",
        "UNET_Model= UNet(encoding_channels=(3,64,128,256,512),decoding_channels=(1024,512,256,128,64),outSize=(seg_map_height,seg_map_width),seg_classes=3)\n",
        "UNET_Model.to(device)\n",
        "\n",
        "print(\"Encoder channels: \",UNET_Model.encoder.channels)\n",
        "print(\"Decoder Channels: \", UNET_Model.decoder.channels)\n",
        "\n",
        "# loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "# # train_sampleimage,train_samplemask=train_dataset.__getitem__(10)\n",
        "# for (batch_index,(image,mask,imagePath,maskPath)) in enumerate(sample_loader):  \n",
        "#   predictions=UNET_Model(image)\n",
        "#   print(\"Image used: \",imagePath)\n",
        "#   print(\"Mask used: \",maskPath)\n",
        "#   print(\"Loss: \",loss_func(predictions,mask))\n",
        "\n",
        "# #the torch.squeeze is done to remove the batch_size dimension from the image, which is usually 1 [batch_size,channels,height,width].\n",
        "\n",
        "# print(\"The data type of the prediction is : \",type(predictions))\n",
        "# predictions=torch.squeeze(predictions)\n",
        "# visualiser_colab(predictions.detach().numpy())\n",
        "# mask=torch.squeeze(mask)\n",
        "# visualiser_colab(mask)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtnAemTrEeDt"
      },
      "source": [
        "Defining the model's hyper-parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0X16dYG6stpo"
      },
      "outputs": [],
      "source": [
        "#defining and initialising model hyper-parameters\n",
        "\n",
        "initial_learning_rate=0.0001\n",
        "\n",
        "#Optimizer function -> Adam\n",
        "optimizer_function= torch.optim.Adam(params=UNET_Model.parameters(),lr=initial_learning_rate)\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "num_epochs=4\n",
        "\n",
        "training_loss_list=[]\n",
        "test_loss_list=[]\n",
        "\n",
        "#loss_func= binary_cross_entropy\n",
        "#loss_function=torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "#loss_func= cross_entropy (as its a 3 class pixel classification problem)\n",
        "\n",
        "'''\n",
        "for CrossEntropyLoss to work, expected mask/target should be either \n",
        "Class indices in the range [0,C) where C is the number of classes or\n",
        "Probabilities for each class\n",
        "'''\n",
        "\n",
        "#What I think is happening: \n",
        "'''\n",
        "Mask data does not contain classes assigned to pixels. It is simply rgb pixel values.\n",
        "\n",
        "image and mask values have been normalized from (0 to 255) to (0,1)\n",
        "so what if CrossEntropyLoss is assuming them to be probability values and as all the values are between\n",
        "0 and 1 (like 0.2, 0.3, 0.5) it is flooring them to be class 0?.\n",
        "\n",
        "'''\n",
        "\n",
        "loss_function=torch.nn.CrossEntropyLoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn-d-EXgstp2"
      },
      "source": [
        "Training the model on the training samples. \n",
        "Calculating loss/error using the loss function. \n",
        "Backpropagating the error through the model, to readjust weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXu_CP2Fstp3",
        "outputId": "b607ccc8-fac8-4a60-a425-0b78842e26a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1516/1516 [22:03<00:00,  1.15it/s]\n",
            "100%|██████████| 1516/1516 [21:49<00:00,  1.16it/s]\n",
            "100%|██████████| 1516/1516 [21:37<00:00,  1.17it/s]\n",
            "100%|██████████| 1516/1516 [21:30<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ended training phase\n",
            "Training losses are as follows:  [1.3157604932785034, 1.2513179779052734, 1.2049356698989868, 1.172764539718628, 1.149619698524475, 1.1328541040420532, 1.1211317777633667, 1.1052088737487793, 1.0847218036651611, 1.0625183582305908, 1.0429304838180542, 1.025288462638855, 1.0097357034683228, 0.9873812198638916, 0.9752857685089111, 0.9578275084495544, 0.9378189444541931, 0.9202964901924133, 0.900331974029541, 0.8841153383255005, 0.8650686144828796, 0.8452746272087097, 0.8325387239456177, 0.8203314542770386, 0.7944661378860474, 0.7848963737487793, 0.7623618841171265, 0.7408679127693176, 0.7304435968399048, 0.7197868824005127, 0.716353714466095, 0.7085871696472168, 0.694856584072113, 0.6809347867965698, 0.6677576303482056, 0.6644300818443298, 0.6659982800483704, 0.6604691743850708, 0.6558393239974976, 0.6563510894775391, 0.6585716009140015, 0.6545947790145874, 0.6516005396842957, 0.6469385027885437, 0.6405749320983887, 0.6339492797851562, 0.6275231838226318, 0.6179063320159912, 0.605216383934021, 0.6267925500869751, 0.6031827330589294, 0.6105198264122009, 0.6143990755081177, 0.606918215751648, 0.6029059886932373, 0.5997540354728699, 0.5972238183021545, 0.5951834321022034, 0.5950402021408081, 0.5965248942375183, 0.5951688885688782, 0.5925915241241455, 0.5869346261024475, 0.5848180055618286, 0.5822214484214783, 0.5840609073638916, 0.5771496891975403, 0.5761823058128357, 0.5670377016067505, 0.5600911378860474, 0.5474397540092468, 0.7421305775642395, 0.7041832804679871, 0.6790934801101685, 0.6345058083534241, 0.5627990961074829, 0.5521223545074463, 0.5495760440826416, 0.5421718955039978, 0.5442975163459778, 0.5418464541435242, 0.5445613265037537, 0.5392967462539673, 0.53630131483078, 0.5437479615211487, 0.543984591960907, 0.5411885976791382, 0.5282195210456848, 0.5257813334465027, 0.5274204015731812, 0.5278646945953369, 0.5246284604072571, 0.5176255106925964, 0.5004838705062866, 0.47654053568840027, 0.4735516905784607, 0.4741513729095459, 0.4656703472137451, 0.4716068208217621, 0.501512348651886, 0.4929502606391907, 0.49169400334358215, 0.48774027824401855, 0.4899762272834778, 0.49201712012290955, 0.485573410987854, 0.48407885432243347, 0.48279064893722534, 0.4774717092514038, 0.48185470700263977, 0.4808187186717987, 0.47450393438339233, 0.4779524505138397, 0.4822929799556732, 0.48201364278793335, 0.48293909430503845, 0.4777385890483856, 0.4767940640449524, 0.4731985330581665, 0.5369288325309753, 0.49851563572883606, 0.4720737338066101, 0.4793809652328491, 0.47442835569381714, 0.4750897288322449, 0.47661495208740234, 0.4745962917804718, 0.45684194564819336, 0.44558870792388916, 0.4430029094219208, 0.4411163330078125, 0.43632885813713074, 0.43470263481140137, 0.44298458099365234, 0.43556761741638184, 0.43854156136512756, 0.43892642855644226, 0.43395254015922546, 0.4391734302043915, 0.44526466727256775, 0.4438481330871582, 0.4398377239704132, 0.4368780255317688, 0.45956355333328247, 0.44523411989212036, 0.44363638758659363, 0.4407292604446411, 0.4226778447628021, 0.4238666892051697, 0.4258790612220764, 0.4489558935165405, 0.4452402889728546, 0.44225186109542847, 0.438715398311615, 0.4376000165939331, 0.4344434440135956, 0.4321903586387634, 0.42985057830810547, 0.42718932032585144, 0.4251159429550171, 0.42302995920181274, 0.42204222083091736, 0.42520013451576233, 0.4186660647392273, 0.4176943004131317, 0.41598591208457947, 0.41268476843833923, 0.4096366763114929, 0.4075583815574646, 0.40627047419548035, 0.4056857228279114, 0.40462449193000793, 0.40177518129348755, 0.40069180727005005, 0.3980831503868103, 0.39570701122283936, 0.3897710144519806, 0.3880279064178467, 0.3897572159767151, 0.39309608936309814, 0.3896206021308899, 0.38293513655662537, 0.3735329508781433, 0.3745206594467163, 0.3706357479095459, 0.36759260296821594, 0.3648137152194977, 0.3702659606933594, 0.372050404548645, 0.37104904651641846, 0.36941447854042053, 0.3675975203514099, 0.3675539493560791, 0.3649826645851135, 0.3663959801197052, 0.3671388030052185, 0.36435526609420776, 0.3617055118083954, 0.36055251955986023, 0.359593003988266, 0.36322736740112305, 0.4305509328842163, 0.36512890458106995, 0.3526945114135742, 0.3562779128551483, 0.36965224146842957, 0.3925122618675232, 0.39085716009140015, 0.3935302793979645, 0.38911303877830505, 0.38241949677467346, 0.3779207468032837, 0.379938542842865, 0.38327136635780334, 0.37667977809906006, 0.3718264102935791, 0.37293004989624023, 0.37266555428504944, 0.3734903931617737, 0.37092339992523193, 0.37241092324256897, 0.3787344992160797, 0.380791038274765, 0.38030195236206055, 0.3818213939666748, 0.37705859541893005, 0.37384143471717834, 0.3733649253845215, 0.37258636951446533, 0.37245744466781616, 0.37660759687423706, 0.37994471192359924, 0.3717501163482666, 0.3503890931606293, 0.3337148427963257, 0.32227200269699097, 0.3186373710632324, 0.3076871633529663, 0.31312230229377747, 0.4680911600589752, 0.4503170847892761, 0.4363444745540619, 0.42928996682167053, 0.42241713404655457, 0.4089866280555725, 0.3966847062110901, 0.3885808289051056, 0.3783843517303467, 0.35710301995277405, 0.341203510761261, 0.35708820819854736, 0.33813029527664185, 0.3505943715572357, 0.35420235991477966, 0.3513534963130951, 0.3458946943283081, 0.35330936312675476, 0.34340614080429077, 0.310016006231308, 0.3186582624912262, 0.35420599579811096, 0.330904096364975, 0.32403162121772766, 0.31933164596557617, 0.31980788707733154, 0.3212931752204895, 0.3180168867111206, 0.3130863904953003, 0.3129649758338928, 0.3092637360095978, 0.31309276819229126, 0.32211923599243164, 0.324372798204422, 0.3226911127567291, 0.3196759521961212, 0.3153412938117981, 0.3179590404033661, 0.31977275013923645, 0.32827651500701904, 0.3216029405593872, 0.3018989562988281, 0.2932121455669403, 0.2998237907886505, 0.2990383803844452, 0.29642048478126526, 0.29507094621658325, 0.29092592000961304, 0.29231059551239014, 0.29476484656333923, 0.294735848903656, 0.29130396246910095, 0.2896290719509125, 0.28819990158081055, 0.2889939546585083, 0.29033347964286804, 0.29006585478782654, 0.2770373821258545, 0.2670612037181854, 0.2680048644542694, 0.26583266258239746, 0.26614925265312195, 0.3496129810810089, 0.32500120997428894, 0.299383282661438, 0.2904976010322571, 0.28015390038490295, 0.2724975049495697, 0.2699202597141266, 0.26959502696990967, 0.2740577757358551, 0.28709203004837036, 0.2926432192325592, 0.2912660837173462, 0.286863774061203, 0.2829938232898712, 0.2809257507324219, 0.28164541721343994, 0.2793204188346863, 0.2831047773361206, 0.2849569022655487, 0.2700110077857971, 0.24806371331214905, 0.2446759045124054, 0.24409954249858856, 0.2444348931312561, 0.28091827034950256, 0.27222681045532227, 0.2685762047767639, 0.2651318311691284, 0.26362866163253784, 0.26090213656425476, 0.25904300808906555, 0.2613033950328827, 0.26568514108657837, 0.26246097683906555, 0.26057252287864685, 0.2591063380241394, 0.25757911801338196, 0.2587648034095764, 0.2606506943702698, 0.24708770215511322, 0.24138110876083374, 0.2390640527009964, 0.23586317896842957, 0.23936451971530914, 0.2388562709093094, 0.23690441250801086, 0.2363823652267456, 0.2370424121618271, 0.2363920956850052, 0.23523811995983124, 0.2375687062740326, 0.2436809092760086, 0.24449223279953003, 0.24072779715061188, 0.23919804394245148, 0.23988710343837738, 0.2405695617198944, 0.24321292340755463, 0.2474437952041626, 0.23738515377044678, 0.22385567426681519, 0.2145608812570572, 0.2154865860939026, 0.21774400770664215, 0.24397294223308563, 0.23899048566818237, 0.2545221745967865, 0.2367648184299469, 0.22856177389621735, 0.22801104187965393, 0.24789148569107056, 0.21643678843975067, 0.22161245346069336, 0.22062475979328156, 0.22195126116275787, 0.2197033315896988, 0.2178936004638672, 0.2163674384355545, 0.21469983458518982, 0.21383094787597656, 0.214145690202713, 0.21372495591640472, 0.21351103484630585, 0.21693049371242523, 0.2179085612297058, 0.21808959543704987, 0.21842887997627258, 0.2175157517194748, 0.21804575622081757, 0.21859274804592133, 0.221279576420784, 0.21270541846752167, 0.20102757215499878, 0.19956928491592407, 0.20266525447368622, 0.20465414226055145, 0.20714110136032104, 0.2048615962266922, 0.2026621550321579, 0.20098578929901123, 0.20221391320228577, 0.20072311162948608, 0.1992931067943573, 0.19897006452083588, 0.20181286334991455, 0.20677365362644196, 0.2130850851535797, 0.21580877900123596, 0.21333454549312592, 0.21210871636867523, 0.21212278306484222, 0.21274995803833008, 0.21364547312259674, 0.21929779648780823, 0.2210012674331665, 0.21145769953727722, 0.19180011749267578, 0.18522018194198608, 0.18313804268836975, 0.1892811805009842, 0.18952496349811554, 0.19249273836612701, 0.19636720418930054, 0.1965358853340149, 0.19508925080299377, 0.1922456920146942, 0.1934146285057068, 0.19437499344348907, 0.19563478231430054, 0.19685550034046173, 0.19741934537887573, 0.19765007495880127, 0.1998206377029419, 0.20852074027061462, 0.21175616979599, 0.21476322412490845, 0.20953775942325592, 0.20717363059520721, 0.20419183373451233, 0.20589065551757812, 0.20746174454689026, 0.2072656899690628, 0.20957545936107635, 0.21000148355960846, 0.20824357867240906, 0.19620640575885773, 0.17803843319416046, 0.17110605537891388, 0.17159293591976166, 0.17064201831817627, 0.17320680618286133, 0.1783767193555832, 0.17776735126972198, 0.17773129045963287, 0.17704908549785614, 0.17814211547374725, 0.17657186090946198, 0.1842268705368042, 0.18742623925209045, 0.18610963225364685, 0.18638533353805542, 0.1884792000055313, 0.1900145709514618, 0.19480901956558228, 0.18955036997795105, 0.1722063273191452, 0.16252103447914124, 0.16246291995048523, 0.16314786672592163, 0.16293592751026154, 0.16334408521652222, 0.16523902118206024, 0.16996189951896667, 0.17341549694538116, 0.1734571009874344, 0.17470882833003998, 0.17461451888084412, 0.17445066571235657, 0.17406761646270752, 0.17314055562019348, 0.17479658126831055, 0.1749815195798874, 0.17410744726657867, 0.1771528720855713, 0.17701488733291626, 0.17730773985385895, 0.17992210388183594, 0.1804208904504776, 0.17984524369239807, 0.1794511377811432, 0.1811373233795166, 0.17925776541233063, 0.16882997751235962, 0.15932846069335938, 0.1528024971485138, 0.14943096041679382, 0.1502416878938675, 0.15654848515987396, 0.1560066044330597, 0.15525983273983002, 0.15454861521720886, 0.15390007197856903, 0.15358875691890717, 0.15316788852214813, 0.15304449200630188, 0.15254689753055573, 0.15293370187282562, 0.15183624625205994, 0.15058216452598572, 0.15223611891269684, 0.15766960382461548, 0.16050966084003448, 0.1581411063671112, 0.15777169167995453, 0.1579219102859497, 0.16134411096572876, 0.16231559216976166, 0.15511421859264374, 0.1424797773361206, 0.14057928323745728, 0.1400044858455658, 0.1465255469083786, 0.14563189446926117, 0.14980435371398926, 0.14555677771568298, 0.147481769323349, 0.14686071872711182, 0.14545874297618866, 0.1447237730026245, 0.15088732540607452, 0.1504725068807602, 0.15549615025520325, 0.1552591621875763, 0.15667939186096191, 0.1572457104921341, 0.1627430021762848, 0.16678859293460846, 0.1516992449760437, 0.13421009480953217, 0.1331678330898285, 0.13262198865413666, 0.13195101916790009, 0.13746336102485657, 0.14070045948028564, 0.14120042324066162, 0.14098580181598663, 0.1422474980354309, 0.1406862437725067, 0.13959497213363647, 0.14046351611614227, 0.14911948144435883, 0.15374131500720978, 0.15410888195037842, 0.15374548733234406, 0.15440434217453003, 0.15412956476211548, 0.1574820578098297, 0.16485916078090668, 0.1611160933971405, 0.1386648714542389, 0.1268235743045807, 0.12751097977161407, 0.12525156140327454, 0.12822672724723816, 0.13556185364723206, 0.13427740335464478, 0.13289962708950043, 0.13266204297542572, 0.1326379030942917, 0.1326126754283905, 0.13330335915088654, 0.13511919975280762, 0.14535582065582275, 0.14931589365005493, 0.14789049327373505, 0.1474766880273819, 0.14889492094516754, 0.1532367765903473, 0.1600227802991867, 0.15437369048595428, 0.13016723096370697, 0.1207018569111824, 0.11999422311782837, 0.1201368197798729, 0.12024684250354767, 0.12765462696552277, 0.12115015834569931, 0.12420907616615295, 0.12595757842063904, 0.1261698305606842, 0.12602964043617249, 0.12600338459014893, 0.1253264993429184, 0.12469140440225601, 0.12424351274967194, 0.12390995770692825, 0.12963634729385376, 0.1366409957408905, 0.1364496499300003, 0.1348617970943451, 0.13310566544532776, 0.13308869302272797, 0.1332673877477646, 0.1380503922700882, 0.13768017292022705, 0.12593112885951996, 0.11559109389781952, 0.11531814187765121, 0.11352992057800293, 0.11413323134183884, 0.11393819749355316, 0.11831231415271759, 0.12187343090772629, 0.1233920231461525, 0.1230621486902237, 0.1227845847606659, 0.12197867035865784, 0.1219950020313263, 0.1214173436164856, 0.12321000546216965, 0.12467348575592041, 0.12634669244289398, 0.1260116696357727, 0.12657463550567627, 0.12577083706855774, 0.12364114075899124, 0.12354215234518051, 0.12363690137863159, 0.13106149435043335, 0.1426839381456375, 0.14230573177337646, 0.13797613978385925, 0.1414954960346222, 0.14621594548225403, 0.1584823727607727, 0.15275587141513824, 0.13012786209583282, 0.10785558074712753, 0.10941143333911896, 0.10659021139144897, 0.11133091151714325, 0.11164622008800507, 0.11259886622428894, 0.1138944998383522, 0.1129944697022438, 0.11192139238119125, 0.11032119393348694, 0.11074412614107132, 0.11777734756469727, 0.12200014293193817, 0.12019983679056168, 0.11881864070892334, 0.11998841166496277, 0.12375536561012268, 0.12854868173599243, 0.12054584175348282, 0.11070545017719269, 0.10096710920333862, 0.10061363875865936, 0.10803002864122391, 0.10822084546089172, 0.10790465027093887, 0.10767466574907303, 0.10749752074480057, 0.10686551779508591, 0.10671454668045044, 0.10849954187870026, 0.10812807083129883, 0.10738558322191238, 0.10721246153116226, 0.10701625794172287, 0.10670249164104462, 0.10702075064182281, 0.11279281228780746, 0.11910790205001831, 0.12235517799854279, 0.12272518873214722, 0.1288929134607315, 0.11848505586385727, 0.11867281049489975, 0.11934274435043335, 0.12020406126976013, 0.12003202736377716, 0.12127133458852768, 0.12622828781604767, 0.13442936539649963, 0.13587148487567902, 0.12953513860702515, 0.11647244542837143, 0.10177598148584366, 0.09897357225418091, 0.09721775352954865, 0.09710505604743958, 0.09738677740097046, 0.09707020223140717, 0.09545896202325821, 0.09462444484233856, 0.10261472314596176, 0.10612565279006958, 0.10677416622638702, 0.10892675817012787, 0.10702020674943924, 0.10674756020307541, 0.10652864724397659, 0.10605630278587341, 0.1062895804643631, 0.10735847055912018, 0.11421437561511993, 0.12134057283401489, 0.1229758933186531, 0.12415469437837601, 0.12625116109848022, 0.125738725066185, 0.1284157782793045, 0.13683177530765533, 0.14173085987567902, 0.1353653520345688, 0.1225971058011055, 0.09857644140720367, 0.09656234085559845, 0.09446972608566284, 0.09451810270547867, 0.09296680241823196, 0.09727310389280319, 0.0977708101272583, 0.09674719721078873, 0.09583829343318939, 0.09547845274209976, 0.09516754001379013, 0.09660452604293823, 0.09668964892625809, 0.09622211009263992, 0.09589157998561859, 0.09471001476049423, 0.09804826974868774, 0.10776060074567795, 0.11114944517612457, 0.10876809805631638, 0.1103971004486084, 0.11366111040115356, 0.12353453040122986, 0.09862855076789856, 0.08707430958747864, 0.09087920933961868, 0.09651516377925873, 0.10403335839509964, 0.1011112853884697, 0.09824921190738678, 0.09551555663347244, 0.10383550077676773, 0.11685656756162643, 0.11536238342523575, 0.11470288038253784, 0.12350263446569443, 0.12208890169858932, 0.08781953155994415, 0.08183005452156067, 0.08273644000291824, 0.10213737189769745, 0.10004016757011414, 0.0983201190829277, 0.09739995747804642, 0.09596506506204605, 0.09467557072639465, 0.0945981964468956, 0.09505248069763184, 0.09440363198518753, 0.09746471047401428, 0.10522601753473282, 0.10867182165384293, 0.10870716720819473, 0.11053439974784851, 0.11562376469373703, 0.10371505469083786, 0.08256656676530838, 0.08080612123012543, 0.08031133562326431, 0.08029129356145859, 0.0914401262998581, 0.0931672528386116, 0.0918956771492958, 0.09234306961297989, 0.09263934195041656, 0.09104496985673904, 0.088621124625206, 0.08790668100118637, 0.09040497988462448, 0.10391271859407425, 0.10609867423772812, 0.10215457528829575, 0.09788018465042114, 0.09602893143892288, 0.09640689939260483, 0.09730934351682663, 0.09918077290058136, 0.09938766807317734, 0.09619373083114624, 0.09612257778644562, 0.08298253268003464, 0.07696044445037842, 0.07505588233470917, 0.074527807533741, 0.08235184848308563, 0.08331985026597977, 0.08436548709869385, 0.08561551570892334, 0.08917629718780518, 0.09147385507822037, 0.09191454946994781, 0.09086557477712631, 0.08706475049257278, 0.08712001144886017, 0.088125079870224, 0.09292872995138168, 0.09601417928934097, 0.10294098407030106, 0.10342787951231003, 0.09982331842184067, 0.09993402659893036, 0.10024184733629227, 0.10050637274980545, 0.10293062031269073, 0.10654552280902863, 0.1060817539691925, 0.09364466369152069, 0.07293529808521271, 0.07229789346456528, 0.08623306453227997, 0.0835345983505249, 0.08118192106485367, 0.08169572800397873, 0.0831485390663147, 0.08296514302492142, 0.08031371235847473, 0.07884207367897034, 0.07977116107940674, 0.07934558391571045, 0.07903482019901276, 0.0800938531756401, 0.08574119210243225, 0.0870964527130127, 0.08624595403671265, 0.08578220009803772, 0.0845920518040657, 0.08341659605503082, 0.08947311341762543, 0.08034562319517136, 0.0695502981543541, 0.068569615483284, 0.06816452741622925, 0.06734694540500641, 0.0672106072306633, 0.07086976617574692, 0.07607762515544891, 0.07649430632591248, 0.07637875527143478, 0.07665038108825684, 0.07604175806045532, 0.07541712373495102, 0.0762549489736557, 0.0842401385307312, 0.0858004242181778, 0.08634975552558899, 0.08812838792800903, 0.08673587441444397, 0.09153752028942108, 0.09251197427511215, 0.08580958098173141, 0.07171972095966339, 0.06780719757080078, 0.06914617121219635, 0.07265777140855789, 0.08040612936019897, 0.07883098721504211, 0.07721661031246185, 0.07618076354265213, 0.07910216599702835, 0.08169757574796677, 0.086892269551754, 0.0985797643661499, 0.10726902633905411, 0.11038945615291595, 0.10550321638584137, 0.10136081278324127, 0.0975436195731163, 0.09968432039022446, 0.10330209881067276, 0.09694579988718033, 0.08663248270750046, 0.07271343469619751, 0.06860023736953735, 0.07342108339071274, 0.07367859035730362, 0.07306371629238129, 0.07204657793045044, 0.071914903819561, 0.07111771404743195, 0.07148122787475586, 0.07214140892028809, 0.07219047844409943, 0.07237304747104645, 0.08092522621154785, 0.08896376937627792, 0.08886434882879257, 0.08431266248226166, 0.0830334797501564, 0.08244291692972183, 0.08265173435211182, 0.08226943761110306, 0.08500626683235168, 0.07003036141395569, 0.06278494745492935, 0.06387095898389816, 0.06296317279338837, 0.06510171294212341, 0.06331212818622589, 0.06387612223625183, 0.06763006746768951, 0.06702065467834473, 0.06621094048023224, 0.0659932792186737, 0.0653192400932312, 0.06647158414125443, 0.07055139541625977, 0.07633897662162781, 0.07803232222795486, 0.07564221322536469, 0.07618658244609833, 0.07725764811038971, 0.07678700238466263, 0.07677219808101654, 0.0839276909828186, 0.07731448113918304, 0.06396733224391937, 0.061930857598781586, 0.06066802144050598, 0.06902392208576202, 0.06585043668746948, 0.06534081697463989, 0.06465139985084534, 0.06585174798965454, 0.06421172618865967, 0.06290974467992783, 0.06335298717021942, 0.07551079243421555, 0.08096791058778763, 0.07888035476207733, 0.0773363783955574, 0.07847049832344055, 0.07740821689367294, 0.07623462378978729, 0.07630795985460281, 0.07630482316017151, 0.06996000558137894, 0.057965297251939774, 0.05773850530385971, 0.05505581945180893, 0.055131085216999054, 0.06183568388223648, 0.06216026842594147, 0.06040239706635475, 0.06126422807574272, 0.06117526814341545, 0.061542704701423645, 0.06310205161571503, 0.061937812715768814, 0.06528551876544952, 0.0738963931798935, 0.07329249382019043, 0.0721123144030571, 0.07066111266613007, 0.07142618298530579, 0.07104744017124176, 0.07146749645471573, 0.07222361862659454, 0.07139834016561508, 0.06285196542739868, 0.05797483026981354, 0.05717584863305092, 0.05533786863088608, 0.06009768322110176, 0.05964125692844391, 0.05890344828367233, 0.05874694883823395, 0.05982023850083351, 0.06143006682395935, 0.06743848323822021, 0.07117129117250443, 0.07306939363479614, 0.07081890106201172, 0.07194267213344574, 0.07097157090902328, 0.07030284404754639, 0.06929907202720642, 0.0703611895442009, 0.0688033327460289, 0.06193111836910248, 0.052374232560396194, 0.05226084962487221, 0.06568395346403122, 0.06616304069757462, 0.06702851504087448, 0.06750722229480743, 0.07417391240596771, 0.0740913450717926, 0.06847082078456879, 0.06562906503677368, 0.07389624416828156, 0.08089827001094818, 0.08319970220327377, 0.08360566198825836, 0.08071870356798172, 0.07828029990196228, 0.07575035095214844, 0.11892931908369064, 0.10083349049091339, 0.0834169015288353, 0.08636946976184845, 0.06194572150707245, 0.055121660232543945, 0.05665838345885277, 0.057343654334545135, 0.07121901214122772, 0.0692838579416275, 0.06726544350385666, 0.0673278197646141, 0.06741981208324432, 0.06709867715835571, 0.06588008999824524, 0.07518769055604935, 0.0845017209649086, 0.08978299051523209, 0.08452097326517105, 0.08197517693042755, 0.08521594852209091, 0.08917131274938583, 0.0836280807852745, 0.07492212951183319, 0.06777681410312653, 0.0599820576608181, 0.06328965723514557, 0.0565660186111927, 0.051067255437374115, 0.049500808119773865, 0.059249505400657654, 0.06055082008242607, 0.05943956598639488, 0.05880163609981537, 0.05704333633184433, 0.058778971433639526, 0.060360945761203766, 0.059884630143642426, 0.06310085952281952, 0.07160424441099167, 0.075325146317482, 0.07375018298625946, 0.07165121287107468, 0.07161717861890793, 0.07434575259685516, 0.0779755488038063, 0.07672910392284393, 0.06660667061805725, 0.053076669573783875, 0.05235866457223892, 0.05226634070277214, 0.05551444739103317, 0.05067550390958786, 0.05310220271348953, 0.054988130927085876, 0.051653988659381866, 0.05664120614528656, 0.05827215313911438, 0.057888422161340714, 0.05863936245441437, 0.06358402222394943, 0.07051753252744675, 0.07482850551605225, 0.07570914924144745, 0.07420585304498672, 0.07576773315668106, 0.07549840211868286, 0.07337239384651184, 0.07550348341464996, 0.06730908900499344, 0.05769708380103111, 0.050003379583358765, 0.047656264156103134, 0.044469673186540604, 0.044082555919885635, 0.053688496351242065, 0.06118194758892059, 0.057034462690353394, 0.055552851408720016, 0.05655612424015999, 0.053413692861795425, 0.0532531663775444, 0.05439872294664383, 0.06452499330043793, 0.07058963924646378, 0.06625206023454666, 0.05935109406709671, 0.06204116716980934, 0.06799599528312683, 0.06786929816007614, 0.06666724383831024, 0.05518392473459244, 0.04614382982254028, 0.04675303399562836, 0.04695838689804077, 0.05447624251246452, 0.07020506262779236, 0.06909248977899551, 0.051543280482292175, 0.05242134630680084, 0.05253944918513298, 0.0546293631196022, 0.05293140560388565, 0.05523724853992462, 0.05509359389543533, 0.05355796962976456, 0.05462419614195824, 0.06299655139446259, 0.06509556621313095, 0.06483297049999237, 0.06625697016716003, 0.06969138979911804, 0.05941354110836983, 0.06512218713760376, 0.07474565505981445, 0.07585285604000092, 0.06978190690279007, 0.05581109970808029, 0.04677752032876015, 0.047312941402196884, 0.053083743900060654, 0.05112673342227936, 0.048728592693805695, 0.04795371741056442, 0.04750814661383629, 0.04700011387467384, 0.047048419713974, 0.04923899099230766, 0.05134086683392525, 0.05491229519248009, 0.054470911622047424, 0.05435967817902565, 0.053394168615341187, 0.052727945148944855, 0.050934839993715286, 0.050003353506326675, 0.05405016988515854, 0.047822121530771255, 0.039177849888801575, 0.03904714435338974, 0.03844023123383522, 0.04391481354832649, 0.045348577201366425, 0.04559415578842163, 0.04535096138715744, 0.04635456204414368, 0.049563050270080566, 0.04764966666698456, 0.048874955624341965, 0.05357838794589043, 0.05695087090134621, 0.05750346556305885, 0.054315172135829926, 0.0539994053542614, 0.05184979364275932, 0.051401447504758835, 0.0613870769739151, 0.06522689014673233, 0.054188281297683716, 0.04185144230723381, 0.039313916116952896, 0.03937671333551407, 0.03948039934039116, 0.04367434233427048, 0.04295821860432625, 0.04516169801354408, 0.047352977097034454, 0.04593036696314812, 0.04531954601407051, 0.049916721880435944, 0.0544610470533371, 0.05577749013900757, 0.05280595272779465, 0.0585300587117672, 0.06065192073583603, 0.07454650849103928, 0.06082566827535629, 0.05943159759044647, 0.06768918037414551, 0.074234239757061, 0.06050928309559822, 0.05977210775017738, 0.047799523919820786, 0.04823476821184158, 0.06339894235134125, 0.050271451473236084, 0.05147912725806236, 0.0537262037396431, 0.054229047149419785, 0.056456685066223145, 0.047331202775239944, 0.05498887598514557, 0.05921996012330055, 0.060376156121492386, 0.058807916939258575, 0.058318816125392914, 0.05764191225171089, 0.05926857888698578, 0.06606381386518478, 0.0628027468919754, 0.04420284181833267, 0.035539451986551285, 0.035705484449863434, 0.03541126847267151, 0.04734271764755249, 0.04733259230852127, 0.04650711268186569, 0.04689532890915871, 0.04505227506160736, 0.04596933349967003, 0.04669220745563507, 0.047259677201509476, 0.059889718890190125, 0.06801919639110565, 0.06917905062437057, 0.07040750980377197, 0.06959466636180878, 0.0691385492682457, 0.06541002541780472, 0.06549692898988724, 0.04450614005327225, 0.04183684289455414, 0.03940248861908913, 0.049329351633787155, 0.05976482108235359, 0.05573057383298874, 0.04895327612757683, 0.04655836895108223, 0.046743154525756836, 0.04695232957601547, 0.05102542042732239, 0.05767720192670822, 0.06013621762394905, 0.05973965302109718, 0.05786323547363281, 0.05549757555127144, 0.05430954322218895, 0.05377769097685814, 0.05901604890823364, 0.05733642727136612, 0.0570981502532959, 0.052449386566877365, 0.042872361838817596, 0.03983806446194649, 0.03593546524643898, 0.03426673635840416, 0.0332346074283123, 0.03612566366791725, 0.055320773273706436, 0.05967776104807854, 0.058432865887880325, 0.05523306503891945, 0.05553736165165901, 0.06535518914461136, 0.07482753694057465, 0.07381287962198257, 0.07451402395963669, 0.08218134194612503, 0.08385057002305984, 0.07155117392539978, 0.06284071505069733, 0.0523432232439518, 0.05318106338381767, 0.04347103834152222, 0.04169436916708946, 0.03975806385278702, 0.03867827355861664, 0.03915778547525406, 0.04030304029583931, 0.04039394482970238, 0.03869685158133507, 0.03809845447540283, 0.03904000297188759, 0.04007245972752571, 0.04361403360962868, 0.052484821528196335, 0.054398998618125916, 0.05113522708415985, 0.05166509002447128, 0.05594762787222862, 0.08789714425802231, 0.10015878826379776, 0.09797461330890656, 0.07548852264881134, 0.04929802939295769, 0.0360567606985569, 0.037177883088588715, 0.03515649959445, 0.0366070456802845, 0.044426079839468, 0.044176239520311356, 0.042258068919181824, 0.04725392535328865, 0.04258739575743675, 0.0419493243098259, 0.041089773178100586, 0.040813643485307693, 0.040861841291189194, 0.040352560579776764, 0.041117094457149506, 0.04613454267382622, 0.0538158155977726, 0.05564704164862633, 0.05495654046535492, 0.05282624065876007, 0.05389679595828056, 0.054950837045907974, 0.054120250046253204, 0.04214460402727127, 0.03418949618935585, 0.035396888852119446, 0.03902500122785568, 0.04305450618267059, 0.04047000780701637, 0.03772623836994171, 0.037503767758607864, 0.038350909948349, 0.038684021681547165, 0.03732617199420929, 0.03958295285701752, 0.04266053065657616, 0.04405619949102402, 0.041361384093761444, 0.045129723846912384, 0.04937637597322464, 0.04983705282211304, 0.049720730632543564, 0.048546869307756424, 0.04825224354863167, 0.04708223044872284, 0.052032988518476486, 0.04826655983924866, 0.03844816982746124, 0.032429635524749756, 0.0306644719094038, 0.03602907806634903, 0.03707500547170639, 0.03756753355264664, 0.03821834549307823, 0.03823805972933769, 0.03973863646388054, 0.04277590289711952, 0.045195091515779495, 0.047099094837903976, 0.049711525440216064, 0.050287362188100815, 0.050769612193107605, 0.04980736970901489, 0.04971865192055702, 0.048559390008449554, 0.05007066950201988, 0.05824266001582146, 0.05255437642335892, 0.03629817068576813, 0.028700198978185654, 0.027975086122751236, 0.02734018862247467, 0.027579400688409805, 0.028315892443060875, 0.028250006958842278, 0.0339784137904644, 0.03918519616127014, 0.03816894069314003, 0.03748619183897972, 0.036569200456142426, 0.03710278868675232, 0.037273574620485306, 0.03683070093393326, 0.03668102249503136, 0.03810335695743561, 0.04322383180260658, 0.048569001257419586, 0.05103883519768715, 0.050806354731321335, 0.04754624515771866, 0.04539378732442856, 0.0456370934844017, 0.05477825924754143, 0.051893047988414764, 0.038524556905031204, 0.02852991782128811, 0.028158962726593018, 0.027920804917812347, 0.03275231644511223, 0.037090662866830826, 0.039550140500068665, 0.042986854910850525, 0.058263637125492096, 0.05190682038664818, 0.04646710306406021, 0.04716432839632034, 0.04309496283531189, 0.05279850959777832, 0.06204638630151749, 0.06855042278766632, 0.06952580064535141, 0.06360604614019394, 0.06112678721547127, 0.05705105885863304, 0.05976128578186035, 0.06837484985589981, 0.07095924019813538, 0.05913276970386505, 0.04170073941349983, 0.03237125277519226, 0.028877127915620804, 0.028607184067368507, 0.035490021109580994, 0.04451043903827667, 0.045970842242240906, 0.03997638076543808, 0.03624800220131874, 0.03921439126133919, 0.055420782417058945, 0.05872698873281479, 0.05931708961725235, 0.055630650371313095, 0.05241112411022186, 0.0337824672460556, 0.03211599960923195, 0.028693940490484238, 0.026880905032157898, 0.031145034357905388, 0.03193800896406174, 0.03210904449224472, 0.03128805756568909, 0.030471287667751312, 0.03039519675076008, 0.031084805727005005, 0.03410281240940094, 0.040789563208818436, 0.04613429680466652, 0.04570086672902107, 0.043066710233688354, 0.04478025808930397, 0.05332183092832565, 0.042807385325431824, 0.047562070190906525, 0.028780916705727577, 0.02610311657190323, 0.02507171779870987, 0.03254031017422676, 0.036590129137039185, 0.03938208520412445, 0.04083501547574997, 0.03713211417198181, 0.036740511655807495, 0.037052564322948456, 0.0354253426194191, 0.03442419320344925, 0.036747779697179794, 0.04107282683253288, 0.04339287057518959, 0.044062238186597824, 0.04341595619916916, 0.044867921620607376, 0.04702538996934891, 0.04646753519773483, 0.045421116054058075, 0.03588224947452545, 0.025136267766356468, 0.0245113093405962, 0.02474956214427948, 0.02365037053823471, 0.03094993345439434, 0.036795031279325485, 0.03525146469473839, 0.03577449172735214, 0.03464755043387413, 0.034151554107666016, 0.033748809248209, 0.03469333425164223, 0.034702979028224945, 0.03320452198386192, 0.033399276435375214, 0.0338919535279274, 0.03430090472102165, 0.03414604440331459, 0.034640103578567505, 0.03600475937128067, 0.04729355126619339, 0.0531434528529644, 0.0506945438683033, 0.05228490009903908, 0.0522962249815464, 0.051045097410678864, 0.049202870577573776, 0.04971915856003761, 0.04896409064531326, 0.04775743559002876, 0.04318543151021004, 0.045433372259140015, 0.060232292860746384, 0.05503750219941139, 0.04073807969689369, 0.026826687157154083, 0.02599114552140236, 0.0253155417740345, 0.02447877824306488, 0.02551117353141308, 0.024987194687128067, 0.031435608863830566, 0.030528409406542778, 0.029323915019631386, 0.02968692034482956, 0.03530288115143776, 0.03314035013318062, 0.03033679537475109, 0.0325041227042675, 0.038366593420505524, 0.03561839461326599, 0.03314082697033882, 0.03259308636188507, 0.04130459949374199, 0.046079400926828384, 0.044960349798202515, 0.04276106879115105, 0.04213133826851845, 0.035964302718639374, 0.03798079863190651, 0.045097388327121735, 0.04202365130186081, 0.03148325905203819, 0.023949479684233665, 0.0240668673068285, 0.023337483406066895, 0.021981878206133842, 0.023587850853800774, 0.02301092818379402, 0.029969392344355583, 0.034600548446178436, 0.03389387205243111, 0.0351368673145771, 0.0359012670814991, 0.03892546147108078, 0.04123144596815109, 0.041823215782642365, 0.041911832988262177, 0.04213139787316322, 0.040678687393665314, 0.04899661988019943, 0.05318382754921913, 0.0503087118268013, 0.044451385736465454, 0.04417272284626961, 0.04400922358036041, 0.04223134368658066, 0.042437050491571426, 0.04714440926909447, 0.04091997444629669, 0.02482360042631626, 0.02212223783135414, 0.021860701963305473, 0.030822865664958954, 0.03191575035452843, 0.030523978173732758, 0.02983718179166317, 0.031031006947159767, 0.03167077153921127, 0.04178686812520027, 0.04718813672661781, 0.048644982278347015, 0.04396715760231018, 0.039809469133615494, 0.042164433747529984, 0.0454251728951931, 0.048572517931461334, 0.051268644630908966, 0.04548896104097366, 0.03451576828956604, 0.02693951316177845, 0.04083162918686867, 0.06163938343524933, 0.05938921496272087, 0.07774966955184937, 0.03305758535861969, 0.03340590000152588, 0.02961627021431923, 0.03143857792019844, 0.03164554759860039, 0.03208494558930397, 0.03278733044862747, 0.03549114242196083, 0.035404253751039505, 0.03717804700136185, 0.04929812252521515, 0.05203013867139816, 0.05371762439608574, 0.043148599565029144, 0.04287116229534149, 0.03995642066001892, 0.03897140175104141, 0.042265452444553375, 0.04398768022656441, 0.03763609007000923, 0.027479341253638268, 0.025423631072044373, 0.02510673925280571, 0.023403607308864594, 0.023286087438464165, 0.021419543772935867, 0.030323458835482597, 0.03272956982254982, 0.03014928288757801, 0.030068855732679367, 0.030174316838383675, 0.02923915721476078, 0.028216784819960594, 0.030291670933365822, 0.03047131560742855, 0.02842218428850174, 0.02681059017777443, 0.026048922911286354, 0.026099637150764465, 0.026987621560692787, 0.030088268220424652, 0.03572678565979004, 0.03730602562427521, 0.03873547911643982, 0.04241746664047241, 0.0409761518239975, 0.0352703295648098, 0.03519430011510849, 0.03846168890595436, 0.04350395128130913, 0.048364754766225815, 0.060250815004110336, 0.0661124661564827, 0.04222485050559044, 0.022483959794044495, 0.026827676221728325, 0.02883138507604599, 0.027781745418906212, 0.0289464108645916, 0.02681121602654457, 0.029711294919252396, 0.03458453342318535, 0.034464478492736816, 0.03566011041402817, 0.044155217707157135, 0.049749620258808136, 0.047206126153469086, 0.04747067764401436, 0.04493028298020363, 0.04385176673531532, 0.04233037307858467, 0.04185114800930023, 0.033135365694761276, 0.02344704419374466, 0.021130340173840523, 0.022972244769334793, 0.03597840294241905, 0.029163377359509468, 0.02304225228726864, 0.022420497611165047, 0.02297942526638508, 0.0242498517036438, 0.024651626124978065, 0.024903850629925728, 0.024718675762414932, 0.023464899510145187, 0.023089630529284477, 0.024379229173064232, 0.025032954290509224, 0.02463638223707676, 0.024252578616142273, 0.02566571719944477, 0.0305070448666811, 0.031391438096761703, 0.02812400832772255, 0.02967825159430504, 0.03327995166182518, 0.03369878977537155, 0.03175264596939087, 0.032687410712242126, 0.032103292644023895, 0.03130882605910301, 0.030199436470866203, 0.029569145292043686, 0.031784456223249435, 0.034488044679164886, 0.03522159159183502, 0.03086170181632042, 0.026461642235517502, 0.022295968607068062, 0.023826459422707558, 0.022101588547229767, 0.021094290539622307, 0.023954248055815697, 0.026475630700588226, 0.027637768536806107, 0.024911269545555115, 0.023728175088763237, 0.024058310315012932, 0.02728843316435814, 0.03275862708687782, 0.036272093653678894, 0.0340753048658371, 0.03247416019439697, 0.0322406142950058, 0.033284857869148254, 0.03440476581454277, 0.03643908351659775, 0.027553079649806023, 0.021160244941711426, 0.01911664567887783, 0.019049009308218956, 0.020844319835305214, 0.0200217142701149, 0.03187018632888794, 0.03204338252544403, 0.03097563050687313, 0.0324072539806366, 0.03321633115410805, 0.03180071711540222, 0.03026697225868702, 0.0312994085252285, 0.03142731636762619, 0.027638737112283707, 0.02664593793451786, 0.03094843402504921, 0.04859992861747742, 0.06536491960287094, 0.060677602887153625, 0.05846240371465683, 0.05494961515069008, 0.049117833375930786, 0.04890534281730652, 0.04627063870429993, 0.04723498970270157, 0.053319286555051804, 0.06373538821935654, 0.06426083296537399, 0.05644875392317772, 0.046721767634153366, 0.039997197687625885, 0.027630144730210304, 0.02761075645685196, 0.020478343591094017, 0.02506149373948574, 0.06897789239883423, 0.06702373921871185, 0.058488648384809494, 0.060171812772750854, 0.06549189239740372, 0.05891513079404831, 0.0566415935754776, 0.06540610641241074, 0.05510316789150238, 0.02619025483727455, 0.022105537354946136, 0.036951787769794464, 0.03894304484128952, 0.06922132521867752, 0.07750452309846878, 0.0627836138010025, 0.0654219388961792, 0.060015685856342316, 0.06223103404045105, 0.028253603726625443, 0.029797706753015518, 0.026643235236406326, 0.028281768783926964, 0.026853861287236214, 0.026285620406270027, 0.02556045912206173, 0.027363227680325508, 0.02658354490995407, 0.025624925270676613, 0.024634718894958496, 0.026474181562662125, 0.034429971128702164, 0.04272586852312088, 0.04279065132141113, 0.041081756353378296, 0.037940286099910736, 0.0368870384991169, 0.03564486652612686, 0.034769948571920395, 0.0401485413312912, 0.03508172929286957, 0.03250526636838913, 0.01893014833331108, 0.03747473657131195, 0.024033259600400925, 0.022037576884031296, 0.02331625111401081, 0.02256038784980774, 0.02958262711763382, 0.03598097339272499, 0.03232667222619057, 0.03051557019352913, 0.029070042073726654, 0.03145372122526169, 0.028562000021338463, 0.02875523269176483, 0.03426210954785347, 0.024244099855422974, 0.016538487747311592, 0.018557492643594742, 0.01824217103421688, 0.020261550322175026, 0.02654958888888359, 0.025782804936170578, 0.024404916912317276, 0.023440498858690262, 0.02254479192197323, 0.022320453077554703, 0.02273891679942608, 0.025963179767131805, 0.03391953185200691, 0.049418628215789795, 0.05029512569308281, 0.04531692713499069, 0.04195041581988335, 0.03996598348021507, 0.041410405188798904, 0.039844051003456116, 0.035650357604026794, 0.04116009920835495, 0.045547861605882645, 0.03226153925061226, 0.018765851855278015, 0.020295677706599236, 0.01679728366434574, 0.01571754179894924, 0.02491534687578678, 0.024479303508996964, 0.023056192323565483, 0.022803790867328644, 0.020827392116189003, 0.024705270305275917, 0.026736807078123093, 0.026784555986523628, 0.0293862447142601, 0.02812708355486393, 0.026399655267596245, 0.028255710378289223, 0.026715833693742752, 0.025948259979486465, 0.032486166805028915, 0.028765862807631493, 0.0161275751888752, 0.015710536390542984, 0.01760195568203926, 0.021068179979920387, 0.021821970120072365, 0.021645398810505867, 0.02133096754550934, 0.02184315398335457, 0.033237751573324203, 0.03686855360865593, 0.036657508462667465, 0.036481913179159164, 0.035380665212869644, 0.033012911677360535, 0.030298780649900436, 0.029201122000813484, 0.027417117729783058, 0.03065839782357216, 0.033934690058231354, 0.029221205040812492, 0.019983943551778793, 0.015384050086140633, 0.01476373802870512, 0.018897676840424538, 0.023556049913167953, 0.0301767997443676, 0.05385506525635719, 0.03223220631480217, 0.024135813117027283, 0.02906815893948078, 0.04376563802361488, 0.018403707072138786, 0.024798812344670296, 0.019739989191293716, 0.01973242312669754, 0.019499124959111214, 0.018732333555817604, 0.020907841622829437, 0.019233079627156258, 0.016890499740839005, 0.018388064578175545, 0.021141350269317627, 0.028341852128505707, 0.029921147972345352, 0.025749722495675087, 0.025518648326396942, 0.026285868138074875, 0.027787648141384125, 0.025501463562250137, 0.023616541177034378, 0.032046716660261154, 0.025422032922506332, 0.014537259936332703, 0.015326732769608498, 0.015862176194787025, 0.020737119019031525, 0.025518588721752167, 0.024248197674751282, 0.023325251415371895, 0.022239968180656433, 0.02160223200917244, 0.02102220058441162, 0.021970447152853012, 0.02172517031431198, 0.024239199236035347, 0.03682231530547142, 0.04386390745639801, 0.039768148213624954, 0.03233842924237251, 0.03273879364132881, 0.03596215322613716, 0.033792607486248016, 0.032305702567100525, 0.03359851613640785, 0.031298644840717316, 0.02706790156662464, 0.022841699421405792, 0.02174610272049904, 0.021776873618364334, 0.0275210402905941, 0.02734355628490448, 0.027223123237490654, 0.0337945893406868, 0.03254861384630203, 0.03135639429092407, 0.028949957340955734, 0.028213784098625183, 0.02792898193001747, 0.02799423784017563, 0.029840853065252304, 0.02941104769706726, 0.027436474338173866, 0.02889992482960224, 0.038466501981019974, 0.04098380357027054, 0.04072114825248718, 0.03993798792362213, 0.03863728418946266, 0.03397540748119354, 0.03687497228384018, 0.04026321694254875, 0.04241809621453285, 0.04300351440906525, 0.04194474592804909, 0.03865348920226097, 0.02901415526866913, 0.02016395516693592, 0.017921552062034607, 0.018756624311208725, 0.01537211425602436, 0.01645766943693161, 0.022574247792363167, 0.020875774323940277, 0.019957274198532104, 0.02272830344736576, 0.02419496327638626, 0.023437000811100006, 0.03518564626574516, 0.04228110983967781, 0.03688559681177139, 0.03091650828719139, 0.030179902911186218, 0.02767784520983696, 0.028214767575263977, 0.025571737438440323, 0.019817348569631577, 0.015684053301811218, 0.015103192068636417, 0.013288610614836216, 0.0133365448564291, 0.018723299726843834, 0.024890001863241196, 0.021192092448472977, 0.02068450301885605, 0.021722067147493362, 0.023364979773759842, 0.02214675396680832, 0.021280813962221146, 0.020872812718153, 0.02042144350707531, 0.02172950468957424, 0.02539970725774765, 0.02929093688726425, 0.03012303076684475, 0.03224639594554901, 0.028982089832425117, 0.029805660247802734, 0.032068196684122086, 0.029950784519314766, 0.027939286082983017, 0.028605254366993904, 0.026396121829748154, 0.02161261811852455, 0.017088348045945168, 0.013912754133343697, 0.012452693656086922, 0.01392668392509222, 0.017885103821754456, 0.017066020518541336, 0.017437726259231567, 0.017809409648180008, 0.01832231506705284, 0.017770390957593918, 0.018975377082824707, 0.018275616690516472, 0.017381027340888977, 0.01663016900420189, 0.016419226303696632, 0.015742599964141846, 0.01724957302212715, 0.02677631936967373, 0.030960604548454285, 0.025506436824798584, 0.02317572943866253, 0.023548660799860954, 0.022575275972485542, 0.02261599898338318, 0.019605262205004692, 0.01398420613259077, 0.011963210068643093, 0.012072890065610409, 0.017286596819758415, 0.020624767988920212, 0.030406994745135307, 0.0168814305216074, 0.02654111199080944, 0.017054814845323563, 0.022951580584049225, 0.025879226624965668, 0.02526088058948517, 0.03394134342670441, 0.040072500705718994, 0.03642769902944565, 0.032669536769390106, 0.02892034687101841, 0.03216560557484627, 0.02776777744293213, 0.020565349608659744, 0.012836627662181854, 0.012795263901352882, 0.01253555528819561, 0.012389066629111767, 0.017225712537765503, 0.020235257223248482, 0.01820511743426323, 0.01709514483809471, 0.0185585655272007, 0.020610470324754715, 0.025260640308260918, 0.024534674361348152, 0.033280033618211746, 0.029738405719399452, 0.03393099084496498, 0.029507484287023544, 0.042353980243206024, 0.028994597494602203, 0.02934040129184723, 0.04006754606962204, 0.04769153147935867, 0.021801387891173363, 0.012463172897696495, 0.012582173570990562, 0.011755581945180893, 0.015452699735760689, 0.027653144672513008, 0.02440379187464714, 0.019914329051971436, 0.017300644889473915, 0.016354110091924667, 0.016411203891038895, 0.019897932186722755, 0.027748657390475273, 0.04506753385066986, 0.04613916203379631, 0.03943747282028198, 0.030691025778651237, 0.029800476506352425, 0.029620639979839325, 0.03254379332065582, 0.03019668348133564, 0.018389344215393066, 0.012322072871029377, 0.011770559474825859, 0.011434348300099373, 0.011444545350968838, 0.012176056392490864, 0.011865143664181232, 0.014672731049358845, 0.015937723219394684, 0.016141695901751518, 0.016966896131634712, 0.01630408875644207, 0.015685120597481728, 0.015229632146656513, 0.014946646988391876, 0.01587999425828457, 0.022778643295168877, 0.0267941951751709, 0.023335250094532967, 0.020754732191562653, 0.02094915322959423, 0.021815573796629906, 0.020439164713025093, 0.022468289360404015, 0.025357678532600403, 0.01760144904255867, 0.011524179950356483, 0.011249475181102753, 0.011123552918434143, 0.011217277497053146, 0.014992842450737953, 0.01464411336928606, 0.014246639795601368, 0.017151568084955215, 0.018949143588542938, 0.017603235319256783, 0.017241010442376137, 0.01641438901424408, 0.015745356678962708, 0.016500819474458694, 0.017667612060904503, 0.017973236739635468, 0.01797342859208584, 0.018133822828531265, 0.017465872690081596, 0.017862068489193916, 0.0323488749563694, 0.037856992334127426, 0.049023766070604324, 0.04735672473907471, 0.035977546125650406, 0.03550279885530472, 0.04098545014858246, 0.03449956700205803, 0.03648446500301361, 0.034908462315797806, 0.026361243799328804, 0.019771136343479156, 0.015908291563391685, 0.013727894052863121, 0.017403585836291313, 0.028681429103016853, 0.02864655666053295, 0.02585897594690323, 0.016121726483106613, 0.01610332727432251, 0.016268672421574593, 0.017003241926431656, 0.027222953736782074, 0.03249344974756241, 0.028149696066975594, 0.022994542494416237, 0.02345610037446022, 0.02430753968656063, 0.025060616433620453, 0.021276550367474556, 0.019709592685103416, 0.010808432474732399, 0.0107002854347229, 0.021244756877422333, 0.01842665672302246, 0.020339878275990486, 0.015458106994628906, 0.015015635639429092, 0.015385028906166553, 0.01603349670767784, 0.017439818009734154, 0.016398202627897263, 0.016197625547647476, 0.018083661794662476, 0.021759677678346634, 0.021370403468608856, 0.022510258480906487, 0.02260972186923027, 0.025863632559776306, 0.032296258956193924, 0.033732056617736816, 0.0285726860165596, 0.025391697883605957, 0.02509002387523651, 0.02437068521976471, 0.024629319086670876, 0.02322118915617466, 0.023110609501600266, 0.02808242477476597, 0.041173357516527176, 0.039144597947597504, 0.030835527926683426, 0.02297041192650795, 0.01604100875556469, 0.011749347671866417, 0.011386158876121044, 0.01087926235049963, 0.01070482935756445, 0.01069276686757803, 0.010302186943590641, 0.010312290862202644, 0.01782739721238613, 0.0185781791806221, 0.01777375303208828, 0.017757495865225792, 0.0169387124478817, 0.016992194578051567, 0.018435664474964142, 0.01770620234310627, 0.019837064668536186, 0.019891684874892235, 0.023021984845399857, 0.026511775329709053, 0.027705470100045204, 0.029560839757323265, 0.0306245107203722, 0.029571540653705597, 0.0305353794246912, 0.03879699110984802, 0.04297083243727684, 0.03984614089131355, 0.028094546869397163, 0.01345928106456995, 0.011577376164495945, 0.010948171839118004, 0.033991821110248566, 0.03680837154388428, 0.02677808329463005, 0.02498491294682026, 0.024663159623742104, 0.014772375114262104, 0.013300660997629166, 0.015360269695520401, 0.017981350421905518, 0.019294997677206993, 0.022584425285458565, 0.020457196980714798, 0.01777925156056881, 0.02169717289507389, 0.03821717947721481, 0.03458475321531296, 0.025896070525050163, 0.0294613279402256, 0.02819361537694931, 0.04404861107468605, 0.01867508329451084, 0.011809845454990864, 0.01286571379750967, 0.021686140447854996, 0.021152814850211143, 0.018363013863563538, 0.017209596931934357, 0.017528221011161804, 0.022753028199076653, 0.033114057034254074, 0.030059069395065308, 0.02912677824497223, 0.02676483429968357, 0.030560187995433807, 0.013487091287970543, 0.010462242178618908, 0.01213786844164133, 0.01637834496796131, 0.016122344881296158, 0.014605244621634483, 0.014253474771976471, 0.014865877106785774, 0.014641429297626019, 0.015580525621771812, 0.01757754199206829, 0.017429297789931297, 0.02228371798992157, 0.0354425422847271, 0.03799370676279068, 0.030585383996367455, 0.0256560817360878, 0.030627336353063583, 0.018384821712970734, 0.01419124286621809, 0.013397334143519402, 0.014459864236414433, 0.012560711242258549, 0.02505272440612316, 0.023733016103506088, 0.020534668117761612, 0.023222658783197403, 0.019894158467650414, 0.018886299803853035, 0.017354745417833328, 0.015364699997007847, 0.015343401581048965, 0.02325933426618576, 0.03229237720370293, 0.03155999630689621, 0.02701660245656967, 0.02577277645468712, 0.023313751444220543, 0.022442497313022614, 0.019506089389324188, 0.018145103007555008, 0.01725693978369236, 0.020008506253361702, 0.013377410359680653, 0.009397987276315689, 0.00929700955748558, 0.009345387108623981, 0.020955631509423256, 0.02029445394873619, 0.015406466089189053, 0.014435527846217155, 0.015645725652575493, 0.018494796007871628, 0.019173339009284973, 0.017940450459718704, 0.01561795175075531, 0.015245070680975914, 0.0229894258081913, 0.04379832744598389, 0.045793645083904266, 0.04735107347369194, 0.03607774153351784, 0.02387951873242855, 0.025108953937888145, 0.03248833492398262, 0.027022726833820343, 0.02380872331559658, 0.028486881405115128, 0.032131776213645935, 0.026435963809490204, 0.01050545647740364, 0.009840406477451324, 0.012412410229444504, 0.01573481783270836, 0.01750868745148182, 0.019954349845647812, 0.023920943960547447, 0.021557779982686043, 0.017458438873291016, 0.014843428507447243, 0.0161913949996233, 0.016356168314814568, 0.01706414297223091, 0.018213694915175438, 0.021922621876001358, 0.02138133905827999, 0.018814634531736374, 0.019008317962288857, 0.01896754279732704, 0.0180552639067173, 0.032709456980228424, 0.02144162729382515, 0.009495597332715988, 0.009204245172441006, 0.00974814873188734, 0.008901908062398434, 0.009086234495043755, 0.012127358466386795, 0.013625613413751125, 0.01416765432804823, 0.013946533203125, 0.014004761353135109, 0.015546752139925957, 0.0148075632750988, 0.01605258882045746, 0.024808909744024277, 0.027107585221529007, 0.024954847991466522, 0.023776564747095108, 0.020751724019646645, 0.02472398430109024, 0.021647345274686813, 0.019046468660235405, 0.012377657927572727, 0.010195864364504814, 0.00995277613401413, 0.015572432428598404, 0.023989681154489517, 0.02403036504983902, 0.020793050527572632, 0.014607561752200127, 0.01565425470471382, 0.01684904471039772, 0.024257684126496315, 0.03616295009851456, 0.04257502406835556, 0.04226256161928177, 0.040952228009700775, 0.04047801345586777, 0.03853023052215576, 0.03409124165773392, 0.03226654604077339, 0.026571569964289665, 0.020826999098062515, 0.014588206075131893, 0.014020605944097042, 0.020878972485661507, 0.017345374450087547, 0.015975667163729668, 0.016953052952885628, 0.018802126869559288, 0.01898670755326748, 0.01856786198914051, 0.019834300503134727, 0.017390534281730652, 0.017601637169718742, 0.02567295730113983, 0.034940123558044434, 0.031235529109835625, 0.02279772236943245, 0.019835205748677254, 0.01971767470240593, 0.021577205508947372, 0.019744999706745148, 0.022156041115522385, 0.015952538698911667, 0.009232062846422195, 0.010529703460633755, 0.009132491424679756, 0.008696862496435642, 0.008564786985516548, 0.013575616292655468, 0.015808308497071266, 0.013772476464509964, 0.013019013218581676, 0.013894966803491116, 0.01438132394105196, 0.017857205122709274, 0.02070688083767891, 0.021039269864559174, 0.022011535242199898, 0.020649822428822517, 0.02123299241065979, 0.02154558151960373, 0.019975364208221436, 0.019306162372231483, 0.02536403015255928, 0.026938490569591522, 0.010451535694301128, 0.007928688079118729, 0.007955019362270832, 0.01667972467839718, 0.016853924840688705, 0.011953290551900864, 0.01201150193810463, 0.013003621250391006, 0.012587704695761204, 0.012439770624041557, 0.01535508967936039, 0.028552822768688202, 0.030010683462023735, 0.026007957756519318, 0.023064643144607544, 0.020108850672841072, 0.01922607421875, 0.018728045746684074, 0.019070960581302643, 0.020645994693040848, 0.016955306753516197, 0.0091263921931386, 0.00816798023879528, 0.008154112845659256, 0.008194798603653908, 0.011198307387530804, 0.012610985897481441, 0.011941053904592991, 0.016016341745853424, 0.016221681609749794, 0.019687093794345856, 0.024983366951346397, 0.02402600087225437, 0.018334154039621353, 0.019395820796489716, 0.018841054290533066, 0.01823706366121769, 0.019885960966348648, 0.01897016540169716, 0.01634211093187332, 0.01840829849243164, 0.020883530378341675, 0.021455097943544388, 0.012978827580809593, 0.007910368032753468, 0.0077895778231322765, 0.009201417677104473, 0.012930139899253845, 0.011625605635344982, 0.011923417448997498, 0.01212097704410553, 0.012355295941233635, 0.01225077174603939, 0.01612272299826145, 0.021159250289201736, 0.021223226562142372, 0.018496785312891006, 0.015562216751277447, 0.016786053776741028, 0.017178595066070557, 0.016647612676024437, 0.018510645255446434, 0.019496209919452667, 0.014560747891664505, 0.008251309394836426, 0.007616675458848476, 0.016932116821408272, 0.021721620112657547, 0.021440304815769196, 0.019287530332803726, 0.026519212871789932, 0.028350815176963806, 0.017101047560572624, 0.016085634008049965, 0.01768544688820839, 0.02084187977015972, 0.029958421364426613, 0.027908682823181152, 0.02516755275428295, 0.023478608578443527, 0.021596508100628853, 0.0785115584731102, 0.06269006431102753, 0.03885278105735779, 0.041722770780324936, 0.02145024761557579, 0.015252618119120598, 0.011226567439734936, 0.012777294963598251, 0.017072565853595734, 0.018638961017131805, 0.020678943023085594, 0.01974480226635933, 0.018626675009727478, 0.01719050481915474, 0.017158811911940575, 0.028140321373939514, 0.03644569218158722, 0.03293609619140625, 0.037600308656692505, 0.03728432580828667, 0.03639376163482666, 0.03161335363984108, 0.027011241763830185, 0.021287795156240463, 0.015462110750377178, 0.009332116693258286, 0.012047955766320229, 0.00941450335085392, 0.014559494331479073, 0.01685936748981476, 0.014849644154310226, 0.01615186408162117, 0.01532011665403843, 0.015006406232714653, 0.015924720093607903, 0.01918211206793785, 0.020263098180294037, 0.01894429884850979, 0.021758265793323517, 0.03001495450735092, 0.02993023209273815, 0.024772265926003456, 0.02499784156680107, 0.02765960618853569, 0.025887999683618546, 0.02744220569729805, 0.025710614398121834, 0.01822688989341259, 0.011966285295784473, 0.008870460093021393, 0.007430688478052616, 0.01276221964508295, 0.01666507124900818, 0.016532052308321, 0.02286684326827526, 0.017987407743930817, 0.023888852447271347, 0.015647416934370995, 0.013623245991766453, 0.015748267993330956, 0.025663601234555244, 0.027216240763664246, 0.028251564130187035, 0.026870843023061752, 0.02261299267411232, 0.025546062737703323, 0.026238318532705307, 0.02539747580885887, 0.03227529674768448, 0.023304812610149384, 0.018311385065317154, 0.009703568182885647, 0.00750328041613102, 0.007209581322968006, 0.007199326064437628, 0.013356858864426613, 0.01700604520738125, 0.01491905190050602, 0.019047720357775688, 0.019174808636307716, 0.01548747904598713, 0.01608353853225708, 0.018522370606660843, 0.023680102080106735, 0.025185810402035713, 0.021044408902525902, 0.020689524710178375, 0.028842821717262268, 0.026793787255883217, 0.030546795576810837, 0.032942283898591995, 0.016946064308285713, 0.007314268033951521, 0.007025105878710747, 0.006962413899600506, 0.01633346453309059, 0.029892858117818832, 0.024935048073530197, 0.01807377301156521, 0.019312214106321335, 0.018871985375881195, 0.02158494107425213, 0.01760341040790081, 0.018955256789922714, 0.0228589940816164, 0.02436554990708828, 0.03103381209075451, 0.02351166121661663, 0.022888606414198875, 0.023173891007900238, 0.024512358009815216, 0.025499463081359863, 0.023873336613178253, 0.026726678013801575, 0.04408267140388489, 0.04036109149456024, 0.02967185713350773, 0.016586322337388992, 0.006945623550564051, 0.006928599905222654, 0.01232815720140934, 0.012263312935829163, 0.01111814845353365, 0.0120816295966506, 0.01329105719923973, 0.012693557888269424, 0.012639963999390602, 0.015106196515262127, 0.016758475452661514, 0.018569311127066612, 0.018760832026600838, 0.015434467233717442, 0.01884602941572666, 0.017281942069530487, 0.015034645795822144, 0.015627790242433548, 0.022074636071920395, 0.01597900502383709, 0.006894596386700869, 0.006719202268868685, 0.0066859121434390545, 0.016417622566223145, 0.020242726430296898, 0.016411958262324333, 0.012655753642320633, 0.015120036900043488, 0.014171842485666275, 0.01161879301071167, 0.017633652314543724, 0.023351488634943962, 0.02401001565158367, 0.019612250849604607, 0.018946994096040726, 0.02336341142654419, 0.018337609246373177, 0.017686812207102776, 0.022027524188160896, 0.02344680204987526, 0.01983761414885521, 0.009663664735853672, 0.007687073666602373, 0.00762417446821928, 0.00745510496199131, 0.012224541045725346, 0.012161937542259693, 0.013182764872908592, 0.015278197824954987, 0.01599751226603985, 0.013732781633734703, 0.012982753105461597, 0.016772285103797913, 0.024551134556531906, 0.022374339401721954, 0.023499013856053352, 0.019741462543606758, 0.03164030984044075, 0.015948161482810974, 0.016900870949029922, 0.02302822470664978, 0.024871015921235085, 0.02428329735994339, 0.01826287992298603, 0.008864808827638626, 0.006496633403003216, 0.008446023799479008, 0.01025067362934351, 0.010690947994589806, 0.01131807453930378, 0.012953197583556175, 0.016559675335884094, 0.01763824187219143, 0.02036866918206215, 0.01973332278430462, 0.016250625252723694, 0.015108805149793625, 0.016817428171634674, 0.015131982043385506, 0.01315874233841896, 0.016279181465506554, 0.01713033951818943, 0.01059857476502657, 0.006437527481466532, 0.006347076501697302, 0.006357769947499037, 0.012212333269417286, 0.011084459722042084, 0.010066439397633076, 0.010055916383862495, 0.00960687454789877, 0.009840927086770535, 0.010447199456393719, 0.010920370928943157, 0.02335203066468239, 0.025380652397871017, 0.025494202971458435, 0.02239958569407463, 0.023301303386688232, 0.028253421187400818, 0.03554406762123108, 0.027306262403726578, 0.01596946455538273, 0.011695747263729572, 0.009212272241711617, 0.012575550004839897, 0.015580305829644203, 0.013856269419193268, 0.013868879526853561, 0.013609085232019424, 0.013392908498644829, 0.01419253833591938, 0.01857784390449524, 0.019032945856451988, 0.01863154023885727, 0.02007702738046646, 0.019053230062127113, 0.01927642524242401, 0.020149076357483864, 0.020587194710969925, 0.02396160364151001, 0.036740437150001526, 0.029334263876080513, 0.019265754148364067, 0.012359163723886013, 0.01655501313507557, 0.008026366122066975, 0.006696201395243406, 0.006546599790453911, 0.010973832570016384, 0.029471825808286667, 0.028001144528388977, 0.017575381323695183, 0.014725999906659126, 0.018663501366972923, 0.021573489531874657, 0.023830723017454147, 0.025162799283862114, 0.04260621592402458, 0.036763571202754974, 0.034605272114276886, 0.02594873681664467, 0.01779652014374733, 0.012713207863271236, 0.00969022884964943, 0.022236185148358345, 0.01165273692458868, 0.011120454408228397, 0.010011826641857624, 0.009325188584625721, 0.009515980258584023, 0.010875813663005829, 0.009573944844305515, 0.009764548391103745, 0.010996080935001373, 0.013070556335151196, 0.01732521690428257, 0.031801074743270874, 0.03700236976146698, 0.02993232198059559, 0.02279718592762947, 0.022318238392472267, 0.057975877076387405, 0.07216286659240723, 0.058205559849739075, 0.038944218307733536, 0.02810581400990486, 0.02479035034775734, 0.029265297576785088, 0.02078593336045742, 0.015684887766838074, 0.01373154204338789, 0.015478386543691158, 0.016076350584626198, 0.021100422367453575, 0.015785586088895798, 0.0134984590113163, 0.01252783928066492, 0.011995665729045868, 0.01144006010144949, 0.011877627111971378, 0.013156103901565075, 0.020604971796274185, 0.028370296582579613, 0.022483428940176964, 0.01792255789041519, 0.020940860733389854, 0.019332023337483406, 0.017659638077020645, 0.017468009144067764, 0.013742325827479362, 0.009090260602533817, 0.007712053135037422, 0.007364897057414055, 0.010436487384140491, 0.011838681995868683, 0.011968359351158142, 0.011541918851435184, 0.011437352746725082, 0.011249670758843422, 0.011454424820840359, 0.016363484784960747, 0.018055547028779984, 0.014887203462421894, 0.01298257615417242, 0.01592596434056759, 0.018938131630420685, 0.01851336658000946, 0.01823219284415245, 0.019955772906541824, 0.01752854324877262, 0.015004179440438747, 0.017506595700979233, 0.015501156449317932, 0.012133334763348103, 0.006536088418215513, 0.0060869804583489895, 0.009189816191792488, 0.009220652282238007, 0.009535755962133408, 0.009885848499834538, 0.010939205065369606, 0.012182827107608318, 0.012875731103122234, 0.013794289901852608, 0.017867401242256165, 0.019713714718818665, 0.01908835954964161, 0.01899808831512928, 0.017908742651343346, 0.01883324608206749, 0.017226019874215126, 0.019622860476374626, 0.027449531480669975, 0.021537229418754578, 0.010502313263714314, 0.00662515964359045, 0.00543954037129879, 0.0053272489458322525, 0.00575087359175086, 0.007639446761459112, 0.009021444246172905, 0.009831255301833153, 0.014070799574255943, 0.013760430738329887, 0.010865665972232819, 0.011659213341772556, 0.012211157940328121, 0.011967477388679981, 0.01155786495655775, 0.010900759138166904, 0.013171505182981491, 0.01570938713848591, 0.018581651151180267, 0.018041113391518593, 0.015611586160957813, 0.01585296541452408, 0.01535628829151392, 0.015795541927218437, 0.022227903828024864, 0.021406538784503937, 0.012191231362521648, 0.00540053378790617, 0.005376019515097141, 0.005372636951506138, 0.007524664979428053, 0.011975225061178207, 0.012398348189890385, 0.013347786851227283, 0.03257996216416359, 0.024992266669869423, 0.01724141463637352, 0.01624026522040367, 0.016451047733426094, 0.02262950874865055, 0.02561245858669281, 0.025616921484470367, 0.024132363498210907, 0.022112803533673286, 0.024492338299751282, 0.023382747545838356, 0.02243875525891781, 0.027653245255351067, 0.033044006675481796, 0.0263432078063488, 0.019557276740670204, 0.0092834597453475, 0.005619799718260765, 0.005865104962140322, 0.01278715766966343, 0.013029498048126698, 0.01481684297323227, 0.013707906939089298, 0.012648485600948334, 0.016251754015684128, 0.03308098018169403, 0.023710947483778, 0.01871156506240368, 0.02055574394762516, 0.0235524233430624, 0.011834323406219482, 0.006776292808353901, 0.005890094209462404, 0.0053889877162873745, 0.01208020281046629, 0.008928344585001469, 0.009010406211018562, 0.00910028163343668, 0.009296911768615246, 0.009035004302859306, 0.009041341952979565, 0.009441697970032692, 0.020324936136603355, 0.017013035714626312, 0.015337066724896431, 0.013043238781392574, 0.016115885227918625, 0.02828166075050831, 0.018263941630721092, 0.028225667774677277, 0.007400724571198225, 0.005255325231701136, 0.005558796692639589, 0.010332493111491203, 0.011962172575294971, 0.014217260293662548, 0.019692309200763702, 0.0158267542719841, 0.014349518343806267, 0.013787487521767616, 0.012010863050818443, 0.011128471232950687, 0.014761831611394882, 0.018294524401426315, 0.020927175879478455, 0.016283981502056122, 0.014572655782103539, 0.01625850982964039, 0.016805587336421013, 0.018233396112918854, 0.016370706260204315, 0.014803547412157059, 0.007885129190981388, 0.005218514706939459, 0.005043238401412964, 0.0049862428568303585, 0.014326496049761772, 0.017572997137904167, 0.01338223647326231, 0.01036151871085167, 0.010550364851951599, 0.010346559807658195, 0.011016655713319778, 0.011059313081204891, 0.012559480033814907, 0.011805810034275055, 0.011212010867893696, 0.011562155559659004, 0.012201434001326561, 0.012370680458843708, 0.012431394308805466, 0.012668555602431297, 0.028308920562267303, 0.03996887058019638, 0.023685287684202194, 0.021028630435466766, 0.023913953453302383, 0.025125088170170784, 0.017852861434221268, 0.020241834223270416, 0.020205911248922348, 0.022775880992412567, 0.015746956691145897, 0.01693599857389927, 0.02664921246469021, 0.026226548478007317, 0.02117132768034935, 0.007810370065271854, 0.0070223198272287846, 0.008016995154321194, 0.009815894067287445, 0.010182212106883526, 0.005736873485147953, 0.010730614885687828, 0.010576161555945873, 0.011074773035943508, 0.011367542669177055, 0.01242286991328001, 0.011781889945268631, 0.011299526318907738, 0.011689659208059311, 0.013944022357463837, 0.011595874093472958, 0.011590495705604553, 0.012988935224711895, 0.01734894886612892, 0.02089318074285984, 0.017352981492877007, 0.017869869247078896, 0.015853669494390488, 0.012338128872215748, 0.01676373928785324, 0.020778030157089233, 0.018834659829735756, 0.012465252541005611, 0.005782394669950008, 0.005954504944384098, 0.004860971588641405, 0.0049737598747015, 0.009428145363926888, 0.010111981071531773, 0.009012637659907341, 0.010092169046401978, 0.011968014761805534, 0.012896336615085602, 0.011997404508292675, 0.010352334007620811, 0.01136862114071846, 0.01142873801290989, 0.011684066615998745, 0.014678836800158024, 0.014117550104856491, 0.017178373411297798, 0.020514586940407753, 0.018219798803329468, 0.014901325106620789, 0.013785979710519314, 0.014893808402121067, 0.01604548469185829, 0.017030585557222366, 0.018025709316134453, 0.017572449520230293, 0.0067941490560770035, 0.004596736282110214, 0.0045665958896279335, 0.009331114590168, 0.008880448527634144, 0.009758374653756618, 0.00952256377786398, 0.009992537088692188, 0.010760144330561161, 0.024750612676143646, 0.02367314323782921, 0.020490160211920738, 0.017053548246622086, 0.01725585013628006, 0.016682427376508713, 0.02112981677055359, 0.02184203267097473, 0.020214593037962914, 0.022566787898540497, 0.012584902346134186, 0.012013884261250496, 0.023764951154589653, 0.03238871693611145, 0.04149075597524643, 0.0560104139149189, 0.015957174822688103, 0.021227743476629257, 0.013785074464976788, 0.013001648709177971, 0.011224130168557167, 0.013299105688929558, 0.014680325984954834, 0.017331959679722786, 0.017059260979294777, 0.017446987330913544, 0.021235428750514984, 0.02291577123105526, 0.030922342091798782, 0.019268197938799858, 0.019042039290070534, 0.017902588471770287, 0.018307704478502274, 0.021641956642270088, 0.022882958874106407, 0.017854763194918633, 0.007191784679889679, 0.010944735258817673, 0.0074533806182444096, 0.009617975912988186, 0.009767964482307434, 0.0048594106920063496, 0.014814669266343117, 0.017152851447463036, 0.010915138758718967, 0.009431026875972748, 0.010732123628258705, 0.00868301372975111, 0.008237138390541077, 0.010099741630256176, 0.01023405697196722, 0.009089076891541481, 0.009050755761563778, 0.009183374233543873, 0.00864409003406763, 0.008632289245724678, 0.010152976028621197, 0.011085864156484604, 0.011253120377659798, 0.01233002170920372, 0.013008590787649155, 0.013544971123337746, 0.013831635005772114, 0.013497518375515938, 0.015905337408185005, 0.019596891477704048, 0.02817373350262642, 0.03714348003268242, 0.04361966252326965, 0.023046880960464478, 0.012867696583271027, 0.010325915180146694, 0.008318898268043995, 0.009303548373281956, 0.008131635375320911, 0.00806031096726656, 0.008474704809486866, 0.011799391359090805, 0.01810337044298649, 0.01560663990676403, 0.02183731086552143, 0.026807274669408798, 0.017739588394761086, 0.01730293035507202, 0.01901206374168396, 0.020757297053933144, 0.019392527639865875, 0.018002068623900414, 0.013230550102889538, 0.00930736307054758, 0.0046549346297979355, 0.004953004885464907, 0.011343341320753098, 0.009212460368871689, 0.009250483475625515, 0.00787208043038845, 0.0074446434155106544, 0.007616023998707533, 0.007432511076331139, 0.007158396765589714, 0.007198098581284285, 0.007457698229700327, 0.007634144742041826, 0.008472596295177937, 0.008369196206331253, 0.008016292005777359, 0.007670348975807428, 0.011341995559632778, 0.015830956399440765, 0.012008201330900192, 0.008663417771458626, 0.010099788196384907, 0.01128303725272417, 0.010745670646429062, 0.010444755665957928, 0.011071228422224522, 0.012640291824936867, 0.011824910528957844, 0.009626567363739014, 0.009359218180179596, 0.011510412208735943, 0.016701526939868927, 0.01751876249909401, 0.009944434277713299, 0.006417441181838512, 0.004161173477768898, 0.0043282657861709595, 0.004328148439526558, 0.004350355826318264, 0.007547601126134396, 0.007405820768326521, 0.008653250522911549, 0.008085563778877258, 0.009534259326756, 0.008999591693282127, 0.012895957566797733, 0.013563466258347034, 0.013681437820196152, 0.01187862642109394, 0.011697877198457718, 0.011877510696649551, 0.011937543749809265, 0.014950711280107498, 0.01910313591361046, 0.012174666859209538, 0.005514882039278746, 0.004020124673843384, 0.007652269210666418, 0.008857659995555878, 0.008106947876513004, 0.014630677178502083, 0.015881773084402084, 0.01652040332555771, 0.018962688744068146, 0.01772601157426834, 0.016206365078687668, 0.014388975687325, 0.012775072827935219, 0.013290374539792538, 0.010761676356196404, 0.010292837396264076, 0.01417718455195427, 0.029061168432235718, 0.036708809435367584, 0.02601824700832367, 0.026911666616797447, 0.02835872583091259, 0.025578735396265984, 0.03112947940826416, 0.028724804520606995, 0.024839280173182487, 0.02839893475174904, 0.03295500576496124, 0.032948728650808334, 0.03363944962620735, 0.029636485502123833, 0.02139008231461048, 0.015745166689157486, 0.007017670664936304, 0.005583134479820728, 0.009986680932343006, 0.012941203080117702, 0.02105177380144596, 0.033918920904397964, 0.045286741107702255, 0.031556207686662674, 0.02001318335533142, 0.01893439330160618, 0.02412259951233864, 0.023213233798742294, 0.009534617885947227, 0.0051231286488473415, 0.01636671833693981, 0.03078414686024189, 0.04705102741718292, 0.03612779825925827, 0.03764549642801285, 0.04517173394560814, 0.06062151491641998, 0.044569578021764755, 0.007164779119193554, 0.006972855888307095, 0.009737693704664707, 0.01184560265392065, 0.011258075945079327, 0.011638734489679337, 0.01123021449893713, 0.01130683720111847, 0.011157941073179245, 0.010577314533293247, 0.00920822937041521, 0.010482006706297398, 0.01473143044859171, 0.016334429383277893, 0.019080722704529762, 0.022829614579677582, 0.01607789844274521, 0.016354583203792572, 0.017350081354379654, 0.016939640045166016, 0.021442066878080368, 0.01770651526749134, 0.016844481229782104, 0.004246185999363661, 0.008225975558161736, 0.011487264186143875, 0.008988329209387302, 0.00886563677340746, 0.007076340727508068, 0.012766418978571892, 0.012541025876998901, 0.013674681074917316, 0.016192195937037468, 0.012399232015013695, 0.010976883582770824, 0.010769172571599483, 0.012084952555596828, 0.015206502750515938, 0.0103237209841609, 0.004440643824636936, 0.0038884091190993786, 0.003800950013101101, 0.006037591490894556, 0.01907951571047306, 0.012532244436442852, 0.01095220260322094, 0.010045408271253109, 0.009668344631791115, 0.009402833878993988, 0.010716106742620468, 0.010117165744304657, 0.013945396989583969, 0.02447466365993023, 0.02473335713148117, 0.02687419019639492, 0.018687615171074867, 0.016725661233067513, 0.01766101084649563, 0.021696362644433975, 0.017783477902412415, 0.023371335119009018, 0.040730640292167664, 0.021446285769343376, 0.008188632316887379, 0.0069511691108345985, 0.006850818637758493, 0.004480551928281784, 0.007407370023429394, 0.00744655542075634, 0.007149695418775082, 0.007472306489944458, 0.007075159344822168, 0.006789109203964472, 0.009025043807923794, 0.010406093671917915, 0.010302291251718998, 0.010188366286456585, 0.00975126028060913, 0.011755680665373802, 0.012705602683126926, 0.011541402898728848, 0.015035493299365044, 0.014074686914682388, 0.004404541105031967, 0.003890380496159196, 0.005715999286621809, 0.008182019926607609, 0.009343259036540985, 0.009270397946238518, 0.009312373585999012, 0.009589952416718006, 0.010470343753695488, 0.015884948894381523, 0.02339416742324829, 0.01632034406065941, 0.01269334927201271, 0.013539209961891174, 0.014593023806810379, 0.015193559229373932, 0.012862934730947018, 0.013394584879279137, 0.016319336369633675, 0.01659972220659256, 0.008314664475619793, 0.0035822729114443064, 0.0035978483501821756, 0.005571279209107161, 0.017170673236250877, 0.014106997288763523, 0.03431711345911026, 0.016265520825982094, 0.010775923728942871, 0.012667963281273842, 0.02084074728190899, 0.008307801559567451, 0.004693057853728533, 0.006610299460589886, 0.010454557836055756, 0.009367397055029869, 0.00738016190007329, 0.0070155286230146885, 0.006275744177401066, 0.006240033078938723, 0.006573465187102556, 0.006991284433752298, 0.012304725125432014, 0.020995043218135834, 0.013584704138338566, 0.011060156859457493, 0.010775186121463776, 0.01128107588738203, 0.010367543436586857, 0.009630857035517693, 0.01057218573987484, 0.009063693694770336, 0.004221273586153984, 0.0066025834530591965, 0.011307158507406712, 0.009528802707791328, 0.008103189058601856, 0.008387704379856586, 0.00937844067811966, 0.009697634726762772, 0.010852780193090439, 0.010487334802746773, 0.010619532316923141, 0.010224221274256706, 0.014847726561129093, 0.02262769266963005, 0.018915850669145584, 0.01361935306340456, 0.013324913568794727, 0.015465155243873596, 0.017772076651453972, 0.01770385541021824, 0.022478636354207993, 0.02078847587108612, 0.01965310238301754, 0.012024364434182644, 0.010189599357545376, 0.007521013263612986, 0.0064238752238452435, 0.028882848098874092, 0.025113508105278015, 0.014063825830817223, 0.013875969685614109, 0.014074327424168587, 0.01447057444602251, 0.015169396996498108, 0.016662245616316795, 0.017911488190293312, 0.020845219492912292, 0.022600049152970314, 0.021813057363033295, 0.018932517617940903, 0.014456800185143948, 0.028703520074486732, 0.024637442082166672, 0.0194181427359581, 0.015557671897113323, 0.016038335859775543, 0.016130059957504272, 0.020530661568045616, 0.02543591894209385, 0.02633921429514885, 0.027570804581046104, 0.029291732236742973, 0.024624839425086975, 0.017343267798423767, 0.011011969298124313, 0.006449138280004263, 0.004045557230710983, 0.004057698883116245, 0.005229365546256304, 0.007839967496693134, 0.012870140373706818, 0.013360945507884026, 0.018784018233418465, 0.02358889766037464, 0.015247543342411518, 0.02067559026181698, 0.019117984920740128, 0.014568925835192204, 0.015558181330561638, 0.01741238310933113, 0.01622852496802807, 0.01716890186071396, 0.0155100729316473, 0.009824398905038834, 0.003327234648168087, 0.0032794782891869545, 0.0033827670849859715, 0.003389275399968028, 0.006435653194785118, 0.012155300006270409, 0.009761178866028786, 0.008857912383973598, 0.009762315079569817, 0.012933936901390553, 0.011906027793884277, 0.010525375604629517, 0.010031260550022125, 0.009760166518390179, 0.01054432988166809, 0.011247103102505207, 0.011532940901815891, 0.01332435104995966, 0.01411588117480278, 0.013481740839779377, 0.014033322222530842, 0.014720361679792404, 0.016242027282714844, 0.014846648089587688, 0.015400291420519352, 0.014787563122808933, 0.010802087374031544, 0.006679655984044075, 0.004710621666163206, 0.0031828568316996098, 0.0035680951550602913, 0.0053359209559857845, 0.005649153608828783, 0.006090871058404446, 0.006032580975443125, 0.006216802168637514, 0.005933590233325958, 0.006091190967708826, 0.006207235623151064, 0.006170773878693581, 0.0062795886769890785, 0.006826485972851515, 0.006770669482648373, 0.007267271168529987, 0.010095120407640934, 0.010999652557075024, 0.009876653552055359, 0.01301528513431549, 0.010629856027662754, 0.010706828907132149, 0.01136225275695324, 0.009834662079811096, 0.0069579086266458035, 0.00308342557400465, 0.0030938666313886642, 0.006434449460357428, 0.009456586092710495, 0.01627519354224205, 0.005819168873131275, 0.010902540758252144, 0.006545993033796549, 0.006591157987713814, 0.006597280036658049, 0.007898793555796146, 0.014133654534816742, 0.011055029928684235, 0.010658732615411282, 0.011668197810649872, 0.011933593079447746, 0.01521490328013897, 0.014948438853025436, 0.010439099743962288, 0.003181823529303074, 0.0031060222536325455, 0.0031077798921614885, 0.0031610738951712847, 0.005482547450810671, 0.006637544371187687, 0.006960230879485607, 0.007976164110004902, 0.008104203268885612, 0.007998833432793617, 0.008299284614622593, 0.009555170312523842, 0.015147358179092407, 0.010711594484746456, 0.011392084881663322, 0.010555189102888107, 0.015560269355773926, 0.011070478707551956, 0.01208540704101324, 0.016792748123407364, 0.026199961081147194, 0.009717747569084167, 0.0030400727409869432, 0.003044434590265155, 0.006011847406625748, 0.0070754848420619965, 0.0110715851187706, 0.008902480825781822, 0.00808164943009615, 0.006709091365337372, 0.007414193823933601, 0.010002478957176208, 0.0067696161568164825, 0.00832876842468977, 0.012718189507722855, 0.012905817478895187, 0.012874365784227848, 0.011675754562020302, 0.014657251536846161, 0.016356728971004486, 0.019713904708623886, 0.016380121931433678, 0.009291944094002247, 0.0035449827555567026, 0.0030204474460333586, 0.002943729981780052, 0.0029963271226733923, 0.004137488082051277, 0.006355985999107361, 0.006247065030038357, 0.0056256395764648914, 0.006451684050261974, 0.006746452767401934, 0.006754436530172825, 0.006310152821242809, 0.005916267167776823, 0.005555107723921537, 0.006079677026718855, 0.008444004692137241, 0.010954438708722591, 0.010225719772279263, 0.009159350767731667, 0.009048670530319214, 0.009041238576173782, 0.009840339422225952, 0.011981460265815258, 0.014172491617500782, 0.00822494924068451, 0.0029834024608135223, 0.0029639897402375937, 0.0029758322052657604, 0.00303348689340055, 0.004058274906128645, 0.006089531350880861, 0.006434645503759384, 0.012211562134325504, 0.01651437021791935, 0.00971713475883007, 0.012585769407451153, 0.007540874183177948, 0.006925980560481548, 0.007807597052305937, 0.008229699917137623, 0.008955903351306915, 0.008568019606173038, 0.008262488059699535, 0.008019606582820415, 0.006498528178781271, 0.012530527077615261, 0.011539813131093979, 0.020088011398911476, 0.021405020728707314, 0.016556765884160995, 0.015352834947407246, 0.01675286702811718, 0.019759543240070343, 0.02732977643609047, 0.02697214111685753, 0.019536934792995453, 0.01120133139193058, 0.003279756987467408, 0.003164896974340081, 0.009272787719964981, 0.012346526607871056, 0.009841752238571644, 0.00847975816577673, 0.007908053696155548, 0.008616107515990734, 0.009872657246887684, 0.010351301170885563, 0.012283166870474815, 0.010931362397968769, 0.009106071665883064, 0.009011284448206425, 0.011182759888470173, 0.012016287073493004, 0.013359702192246914, 0.011350332759320736, 0.013010683469474316, 0.0028587200213223696, 0.00285070831887424, 0.007206273265182972, 0.006525878794491291, 0.0063603948801755905, 0.0068393731489777565, 0.006509367376565933, 0.006551394239068031, 0.007014984264969826, 0.007638132199645042, 0.007291750982403755, 0.007010334637016058, 0.006536674685776234, 0.0062691280618309975, 0.006469285115599632, 0.006316592451184988, 0.010363836772739887, 0.011109276674687862, 0.011709651909768581, 0.011028545908629894, 0.0109091280028224, 0.010029369033873081, 0.010624038986861706, 0.01032695546746254, 0.010776611976325512, 0.013559896498918533, 0.01336590014398098, 0.01437201164662838, 0.0182027630507946, 0.023077746853232384, 0.02108783833682537, 0.012480922974646091, 0.00545861292630434, 0.002987799234688282, 0.0028736782260239124, 0.002726333448663354, 0.0027972019743174314, 0.0034315946977585554, 0.0028227500151842833, 0.0027781426906585693, 0.009763438254594803, 0.01081280317157507, 0.008912574499845505, 0.009390728548169136, 0.008305931463837624, 0.008424771949648857, 0.00857591349631548, 0.008499161340296268, 0.00877748429775238, 0.010027158074080944, 0.015219895169138908, 0.014620018191635609, 0.015527124516665936, 0.01376826036721468, 0.014428608119487762, 0.01505849976092577, 0.01714528352022171, 0.022392557933926582, 0.02709893509745598, 0.026547981426119804, 0.01951940543949604, 0.007656743284314871, 0.0029465544503182173, 0.0030261336360126734, 0.01720208115875721, 0.018895287066698074, 0.014304934069514275, 0.0069810329005122185, 0.01325073093175888, 0.0059704906307160854, 0.006213884800672531, 0.014306243509054184, 0.018528666347265244, 0.015523229725658894, 0.016262101009488106, 0.012288805097341537, 0.00932567473500967, 0.011385137215256691, 0.014512406662106514, 0.015284410677850246, 0.015626221895217896, 0.0160939060151577, 0.016847733408212662, 0.028371503576636314, 0.010137369856238365, 0.004134442191570997, 0.0028035547584295273, 0.010182682424783707, 0.012422949075698853, 0.010220506228506565, 0.008744359016418457, 0.007676042150706053, 0.01382533647119999, 0.033941127359867096, 0.020511003211140633, 0.015683384612202644, 0.016785351559519768, 0.01638244092464447, 0.009420913644134998, 0.00466197170317173, 0.005118866451084614, 0.009869120083749294, 0.007951010949909687, 0.007613285910338163, 0.007211599964648485, 0.007271509617567062, 0.008203050121665001, 0.016472550109028816, 0.017428787425160408, 0.010907124727964401, 0.013385586440563202, 0.01639692857861519, 0.020923618227243423, 0.020067667588591576, 0.014671637676656246, 0.02026529610157013, 0.01121574454009533, 0.00506207998842001, 0.0030487454496324062, 0.003288811771199107, 0.003683771239593625, 0.006672542076557875, 0.005475725047290325, 0.005849804263561964, 0.007941319607198238, 0.01011665165424347, 0.009252188727259636, 0.009180266410112381, 0.008512269705533981, 0.01001005433499813, 0.009265821427106857, 0.008550301194190979, 0.010352949611842632, 0.010936274193227291, 0.011441479437053204, 0.011132922023534775, 0.008780165575444698, 0.008658859878778458, 0.009116174653172493, 0.008982731029391289, 0.013883932493627071, 0.006404199171811342, 0.0027496046386659145, 0.0030900747515261173, 0.002961883321404457, 0.011568374000489712, 0.005742118693888187, 0.005459006875753403, 0.005979498382657766, 0.006921886466443539, 0.009671295993030071, 0.015054319985210896, 0.00995014701038599, 0.007994894869625568, 0.00610615499317646, 0.010049333795905113, 0.018220674246549606, 0.015147070400416851, 0.015762630850076675, 0.013171213679015636, 0.011005253531038761, 0.013211648911237717, 0.021594248712062836, 0.026174740865826607, 0.014423521235585213, 0.015937060117721558, 0.01858338713645935, 0.01722133718430996, 0.0027940943837165833, 0.0027053162921220064, 0.006343942601233721, 0.007650286424905062, 0.006870431359857321, 0.008824062533676624, 0.011711903847754002, 0.01019299402832985, 0.009041506797075272, 0.008283335715532303, 0.008297117426991463, 0.007500969339162111, 0.007630446460098028, 0.007379652466624975, 0.011877138167619705, 0.010026193223893642, 0.008515676483511925, 0.008654178120195866, 0.008265444077551365, 0.007631323765963316, 0.01455213688313961, 0.011613903567194939, 0.0028757958207279444, 0.0025190715678036213, 0.0025096910540014505, 0.0025500934571027756, 0.0025545344687998295, 0.004246610216796398, 0.005423903930932283, 0.005539107136428356, 0.005770052317529917, 0.005891603883355856, 0.005550703499466181, 0.005910376086831093, 0.007654478307813406, 0.010086883790791035, 0.008341571316123009, 0.00868045911192894, 0.009360410273075104, 0.009525121189653873, 0.01046961359679699, 0.011298942379653454, 0.011295258067548275, 0.005524030886590481, 0.0025192624889314175, 0.0024878517724573612, 0.009758539497852325, 0.019217686727643013, 0.01786557026207447, 0.012365485541522503, 0.008862914517521858, 0.009491008706390858, 0.010080196894705296, 0.01143068540841341, 0.016169264912605286, 0.02420843578875065, 0.030224140733480453, 0.0272373016923666, 0.021917641162872314, 0.017504887655377388, 0.02042400650680065, 0.017797712236642838, 0.014138177037239075, 0.015266401693224907, 0.00910769309848547, 0.009392224252223969, 0.01602671667933464, 0.010266765020787716, 0.007963341660797596, 0.008084964007139206, 0.0086177047342062, 0.009258991107344627, 0.008929576724767685, 0.0094253895804286, 0.008342140354216099, 0.008899690583348274, 0.011004923842847347, 0.011968058533966541, 0.011706327088177204, 0.010408088564872742, 0.011096038855612278, 0.012559337541460991, 0.013475390151143074, 0.015132572501897812, 0.01736552268266678, 0.007731966208666563, 0.0024725196417421103, 0.003044392913579941, 0.002514137187972665, 0.0024411743506789207, 0.0025694607757031918, 0.010134492069482803, 0.007341882213950157, 0.005252803210169077, 0.006661627441644669, 0.00687218876555562, 0.006642053369432688, 0.005774293560534716, 0.010536907240748405, 0.012158388271927834, 0.015088336542248726, 0.011403213255107403, 0.009084290824830532, 0.009811175987124443, 0.011912080459296703, 0.012344379909336567, 0.01439500879496336, 0.017611952498555183, 0.004335117992013693, 0.002272430807352066, 0.0022513854783028364, 0.006319972686469555, 0.010698840953409672, 0.00695821875706315, 0.006797895301133394, 0.008346149697899818, 0.006362136919051409, 0.004976765718311071, 0.006945381872355938, 0.008984953165054321, 0.008882301859557629, 0.009264457039535046, 0.009939257055521011, 0.010101213119924068, 0.008916713297367096, 0.009193516336381435, 0.013929401524364948, 0.011251114308834076, 0.010611492209136486, 0.003049794351682067, 0.0023841571528464556, 0.0023223080206662416, 0.0022955250460654497, 0.004658351186662912, 0.0066194916144013405, 0.006032479461282492, 0.012043540365993977, 0.010216478258371353, 0.006240397691726685, 0.005378298461437225, 0.00664170179516077, 0.009846944361925125, 0.010385792702436447, 0.009991269558668137, 0.01073687244206667, 0.01445776503533125, 0.012174026109278202, 0.007364369463175535, 0.008282584138214588, 0.010969591327011585, 0.015257525257766247, 0.008034903556108475, 0.002327574649825692, 0.0023091272450983524, 0.0034316126257181168, 0.006315700709819794, 0.006199120078235865, 0.0059494744054973125, 0.005675342865288258, 0.0062769511714577675, 0.005856245756149292, 0.009052522480487823, 0.009110793471336365, 0.009517996571958065, 0.008894975297152996, 0.008623834699392319, 0.007980997674167156, 0.008690417744219303, 0.00935497134923935, 0.012807321734726429, 0.011824250221252441, 0.009570344351232052, 0.0031773634254932404, 0.0023480041418224573, 0.004676343873143196, 0.006263203918933868, 0.009468160569667816, 0.012865960597991943, 0.015644652768969536, 0.01465750951319933, 0.010791362263262272, 0.01267927885055542, 0.012025922536849976, 0.009237893857061863, 0.012715557590126991, 0.018496721982955933, 0.01811791956424713, 0.011567101813852787, 0.0104436706751585, 0.038811761885881424, 0.05400870740413666, 0.03225678205490112, 0.03322027251124382, 0.0069258385337889194, 0.002513873390853405, 0.0026239552535116673, 0.0039029023610055447, 0.01009916141629219, 0.012033149600028992, 0.014103314839303493, 0.014600859023630619, 0.014010593295097351, 0.01246858760714531, 0.011402358300983906, 0.019461797550320625, 0.018557406961917877, 0.017347071319818497, 0.019748080521821976, 0.024367820471525192, 0.03097248636186123, 0.02240081876516342, 0.01704428531229496, 0.013833806850016117, 0.009933527559041977, 0.005789758637547493, 0.0029085809364914894, 0.00315380678512156, 0.01169662270694971, 0.01410419400781393, 0.00876075029373169, 0.00871620699763298, 0.008527231402695179, 0.008013610728085041, 0.007385330740362406, 0.008297844789922237, 0.008738486096262932, 0.009330768138170242, 0.01017689611762762, 0.011732981540262699, 0.012612249702215195, 0.01169758290052414, 0.011445971205830574, 0.011893478222191334, 0.013287637382745743, 0.017639795318245888, 0.015099147334694862, 0.01157420314848423, 0.006813983898609877, 0.0029547251760959625, 0.002177676185965538, 0.00583049189299345, 0.009240767918527126, 0.00628853403031826, 0.008844106458127499, 0.006281193345785141, 0.007769772782921791, 0.007752068340778351, 0.007501303683966398, 0.0078432597219944, 0.011853618547320366, 0.011975758709013462, 0.012383165769279003, 0.011328290216624737, 0.010919163003563881, 0.01108253188431263, 0.012875648215413094, 0.017282765358686447, 0.019852526485919952, 0.01415182650089264, 0.011893830262124538, 0.010614912956953049, 0.003585126716643572, 0.002246043412014842, 0.0022632109466940165, 0.006466444581747055, 0.010029535740613937, 0.009667444974184036, 0.012734350748360157, 0.012365167960524559, 0.010799013078212738, 0.010965357534587383, 0.009923589415848255, 0.01025458425283432, 0.012625183910131454, 0.011160631664097309, 0.008433820679783821, 0.01177964173257351, 0.01429890189319849, 0.01982131414115429, 0.024513665586709976, 0.011813219636678696, 0.0024055938702076674, 0.0020698646549135447, 0.002714101690798998, 0.010379023849964142, 0.018330780789256096, 0.016097567975521088, 0.007555813528597355, 0.010905166156589985, 0.01008404791355133, 0.012426599860191345, 0.010894399136304855, 0.01038915291428566, 0.01017797738313675, 0.009311961010098457, 0.009693014435470104, 0.011599536053836346, 0.013719224371016026, 0.013992490246891975, 0.011195819824934006, 0.01163987535983324, 0.010872635059058666, 0.013454853557050228, 0.02274145744740963, 0.02499096840620041, 0.020108982920646667, 0.009966758079826832, 0.002297332976013422, 0.002037282567471266, 0.005742394831031561, 0.0063972496427595615, 0.007283051498234272, 0.008906837552785873, 0.009346987120807171, 0.008529533632099628, 0.007877165451645851, 0.0073071797378361225, 0.00829796027392149, 0.00852928962558508, 0.009416069835424423, 0.009186817333102226, 0.00949790608137846, 0.009987051598727703, 0.009855622425675392, 0.00934502575546503, 0.012459046207368374, 0.00866344477981329, 0.0028341314755380154, 0.002029657596722245, 0.0020130458287894726, 0.006432802882045507, 0.01250247098505497, 0.008226954378187656, 0.0065758409909904, 0.007322395220398903, 0.006501876749098301, 0.005497454199939966, 0.008787253871560097, 0.010481452569365501, 0.011521830223500729, 0.016069654375314713, 0.011088702827692032, 0.010423892177641392, 0.009300661273300648, 0.010769417509436607, 0.015035917982459068, 0.016349775716662407, 0.013633759692311287, 0.00497919088229537, 0.003426168579608202, 0.0025474978610873222, 0.002404900500550866, 0.0053539457730948925, 0.007674786727875471, 0.006947716698050499, 0.008527812547981739, 0.009793974459171295, 0.00773530313745141, 0.007316881325095892, 0.010527471080422401, 0.02744627743959427, 0.01608370430767536, 0.013192466460168362, 0.0121147520840168, 0.016164438799023628, 0.011215322650969028, 0.011576118879020214, 0.021756982430815697, 0.02171231620013714, 0.0205239150673151, 0.012500464916229248, 0.00581090385094285, 0.002025551861152053, 0.0041885776445269585, 0.0045449561439454556, 0.005540824960917234, 0.0059660654515028, 0.0058180782943964005, 0.00853385403752327, 0.007494565565139055, 0.010494121350347996, 0.013416646979749203, 0.010948368348181248, 0.008136704564094543, 0.01045343279838562, 0.009783587418496609, 0.010210786946117878, 0.011076729744672775, 0.011385767720639706, 0.005586885381489992, 0.0019319576676934958, 0.0019230414181947708, 0.0019209440797567368, 0.01747441291809082, 0.008547520264983177, 0.006315034814178944, 0.005557371769100428, 0.005003747064620256, 0.00546971894800663, 0.005406245123594999, 0.005677283275872469, 0.016134630888700485, 0.016287505626678467, 0.014602260664105415, 0.013659278862178326, 0.015573832206428051, 0.01864924654364586, 0.025519561022520065, 0.024869872257113457, 0.011368664912879467, 0.004799593705683947, 0.0030609380919486284, 0.00953097827732563, 0.009437467902898788, 0.008551735430955887, 0.008729713037610054, 0.00786194670945406, 0.006989429704844952, 0.00658868532627821, 0.012662995606660843, 0.011337949894368649, 0.009613928385078907, 0.00949596893042326, 0.011967899277806282, 0.012655564583837986, 0.015442514792084694, 0.010471126064658165, 0.011720816604793072, 0.014122074469923973, 0.017108986154198647, 0.013575364835560322, 0.008915572427213192, 0.005339653696864843, 0.0036353287287056446, 0.0031505560036748648, 0.002443585777655244, 0.0068445452488958836, 0.025771334767341614, 0.022932594642043114, 0.010497160255908966, 0.008249353617429733, 0.008361611515283585, 0.013139132410287857, 0.013951046392321587, 0.013421830721199512, 0.02019408345222473, 0.02039247564971447, 0.019937625154852867, 0.015825167298316956, 0.009917818941175938, 0.006384856067597866, 0.005441514775156975, 0.02034864015877247, 0.02202681638300419, 0.009930282831192017, 0.004711419343948364, 0.004568284377455711, 0.005396654363721609, 0.0069570401683449745, 0.006139788776636124, 0.008281837217509747, 0.007733222097158432, 0.007037952542304993, 0.0121057303622365, 0.03092791885137558, 0.032782383263111115, 0.02257417142391205, 0.017861472442746162, 0.01718340814113617, 0.05681869760155678, 0.06945640593767166, 0.06209063529968262, 0.04179977998137474, 0.027766328305006027, 0.02193281054496765, 0.019896425306797028, 0.028194501996040344, 0.02408285066485405, 0.012454909272491932, 0.00893059466034174, 0.009263590909540653, 0.017374176532030106, 0.009886222891509533, 0.008596271276473999, 0.008939815685153008, 0.008999955840408802, 0.00959382951259613, 0.009395402856171131, 0.010291499085724354, 0.017199987545609474, 0.024751950055360794, 0.023500138893723488, 0.01892865262925625, 0.014005673117935658, 0.014557120390236378, 0.014724274165928364, 0.014212239533662796, 0.012324230745434761, 0.005911587737500668, 0.0035825835075229406, 0.006133865099400282, 0.005269218701869249, 0.004951924085617065, 0.00534156383946538, 0.005664973519742489, 0.007347697392106056, 0.009072953835129738, 0.008377601392567158, 0.009507104754447937, 0.008730422705411911, 0.005942600779235363, 0.006136940326541662, 0.008813917636871338, 0.009991639293730259, 0.009683940559625626, 0.010187485255300999, 0.012082783505320549, 0.009870593436062336, 0.010089132934808731, 0.013479534536600113, 0.011042420752346516, 0.00824922788888216, 0.0027395011857151985, 0.002435269532725215, 0.005497287027537823, 0.005311880726367235, 0.005784882232546806, 0.006437217816710472, 0.0065876939333975315, 0.00856337882578373, 0.010206557810306549, 0.009822147898375988, 0.010836080648005009, 0.01398509182035923, 0.014307591132819653, 0.01445681694895029, 0.01405046135187149, 0.014325715601444244, 0.012703615240752697, 0.015757562592625618, 0.023891683667898178, 0.019589656963944435, 0.0072633628733456135, 0.002878595842048526, 0.0020873472094535828, 0.001852956134825945, 0.002277635969221592, 0.0028556783217936754, 0.004984432831406593, 0.005249952897429466, 0.006848669610917568, 0.006719021592289209, 0.006783188786357641, 0.007675770670175552, 0.007879171520471573, 0.0077880858443677425, 0.007343338802456856, 0.006834263447672129, 0.007932768203318119, 0.009951280429959297, 0.012625987641513348, 0.012801943346858025, 0.01044022012501955, 0.009115558117628098, 0.009554087184369564, 0.010862035676836967, 0.0143375713378191, 0.014763861894607544, 0.00824966561049223, 0.001964476890861988, 0.0018941301386803389, 0.0017841013614088297, 0.003091181395575404, 0.005137725733220577, 0.006407927721738815, 0.007682353258132935, 0.01916678249835968, 0.016989829018712044, 0.012130079790949821, 0.009928258135914803, 0.011987810023128986, 0.015200898051261902, 0.018191125243902206, 0.01803559996187687, 0.018206626176834106, 0.013856840319931507, 0.01221467088907957, 0.0113926837220788, 0.013956641778349876, 0.021934915333986282, 0.026578200981020927, 0.021231459453701973, 0.01369265466928482, 0.006472197361290455, 0.003902121214196086, 0.0018826613668352365, 0.00918025802820921, 0.009805606678128242, 0.009557321667671204, 0.009814172983169556, 0.010376323014497757, 0.01377842016518116, 0.03524082526564598, 0.015932949259877205, 0.01247775461524725, 0.014930895529687405, 0.018531864508986473, 0.006136454641819, 0.0018808559980243444, 0.0018276337068527937, 0.0017979496624320745, 0.004580809734761715, 0.00427997624501586, 0.004371826536953449, 0.004581303335726261, 0.004758048336952925, 0.004624706692993641, 0.004760703071951866, 0.005250763148069382, 0.014179703779518604, 0.009250394999980927, 0.008398582227528095, 0.007992311380803585, 0.009887543506920338, 0.01782386563718319, 0.013778186403214931, 0.02643769048154354, 0.0034702930133789778, 0.0017117534298449755, 0.001715501886792481, 0.005148464813828468, 0.006622683722525835, 0.01051260530948639, 0.016323471441864967, 0.0122915618121624, 0.010633962228894234, 0.009255982004106045, 0.007592308335006237, 0.007157342974096537, 0.010447985492646694, 0.013660662807524204, 0.01454499363899231, 0.012959295883774757, 0.011520057916641235, 0.013339661061763763, 0.014992590062320232, 0.01561605092138052, 0.013528051786124706, 0.011151254177093506, 0.0038521033711731434, 0.0017807891126722097, 0.0016342331655323505, 0.0016275374218821526, 0.012248622253537178, 0.020384710282087326, 0.01122915931046009, 0.0063090515322983265, 0.006193823181092739, 0.00606014858931303, 0.00713924877345562, 0.007661314681172371, 0.01032449770718813, 0.009026593528687954, 0.007778899744153023, 0.008133682422339916, 0.008858861401677132, 0.008944321423768997, 0.00913761556148529, 0.009438392706215382, 0.020069066435098648, 0.02590349316596985, 0.01905014179646969, 0.01618744246661663, 0.016950054094195366, 0.020115328952670097, 0.012012050487101078, 0.01247608382254839, 0.013016149401664734, 0.01969108358025551, 0.011438638903200626, 0.011994763277471066, 0.01727418415248394, 0.01820550300180912, 0.0175480917096138, 0.003911081235855818, 0.0019163029501214623, 0.0022992517333477736, 0.0041196406818926334, 0.002987185725942254, 0.001775213866494596, 0.007795853074640036, 0.008334031328558922, 0.00991491787135601, 0.010417534969747066, 0.008967728354036808, 0.00803577620536089, 0.009050645865499973, 0.00935414806008339, 0.009494733065366745, 0.007946033962070942, 0.008793285116553307, 0.0093211829662323, 0.008925781585276127, 0.013220664113759995, 0.009845003485679626, 0.011314037255942822, 0.01007652934640646, 0.009176211431622505, 0.014222239144146442, 0.018174150958657265, 0.014569681137800217, 0.007508722599595785, 0.0019023397471755743, 0.0016429168172180653, 0.0016469289548695087, 0.0017059175297617912, 0.004693884868174791, 0.005433846265077591, 0.00543917715549469, 0.005334547255188227, 0.005513832904398441, 0.007917552255094051, 0.007834341377019882, 0.008357832208275795, 0.00832325592637062, 0.007478795945644379, 0.011834142729640007, 0.00622343085706234, 0.007009736727923155, 0.009601505473256111, 0.01141175627708435, 0.01342680212110281, 0.011323980055749416, 0.010171139612793922, 0.011197017505764961, 0.012278877198696136, 0.012761382386088371, 0.015008332207798958, 0.013919372111558914, 0.004148324951529503, 0.0015356587246060371, 0.00168225250672549, 0.004922150168567896, 0.006934498902410269, 0.006769945379346609, 0.00645050685852766, 0.006254285573959351, 0.006748462561517954, 0.012121029198169708, 0.02024209126830101, 0.022472746670246124, 0.011494840495288372, 0.010506951250135899, 0.01050331350415945, 0.016160210594534874, 0.017202848568558693, 0.015191154554486275, 0.022512849420309067, 0.01285200659185648, 0.002452700398862362, 0.010610575787723064, 0.029127327725291252, 0.03600713610649109, 0.052450310438871384, 0.012280689552426338, 0.008889589458703995, 0.0076209246180951595, 0.007646959740668535, 0.007873796857893467, 0.00895882397890091, 0.01234344020485878, 0.01356805395334959, 0.014698122628033161, 0.011926235631108284, 0.039012521505355835, 0.030461782589554787, 0.014004797674715519, 0.012383152730762959, 0.012431418523192406, 0.012715370394289494, 0.013906527310609818, 0.016019275411963463, 0.018715014681220055, 0.016997521743178368, 0.003989372402429581, 0.002771746600046754, 0.002447333186864853, 0.002372540533542633, 0.0020182188600301743, 0.003270616987720132, 0.010556740686297417, 0.010544800199568272, 0.006343330722302198, 0.005692578852176666, 0.006493126042187214, 0.005993370432406664, 0.005756156984716654, 0.006945916451513767, 0.006251323502510786, 0.005972650367766619, 0.006258261390030384, 0.0058541432954370975, 0.005026224534958601, 0.00525638647377491, 0.006085147615522146, 0.0064909025095403194, 0.006872556172311306, 0.00980126578360796, 0.010781848803162575, 0.01066852081567049, 0.008923785760998726, 0.008497549220919609, 0.009540010243654251, 0.013421065174043179, 0.01863487809896469, 0.04524136334657669, 0.052720434963703156, 0.016545094549655914, 0.0035392101854085922, 0.002499534282833338, 0.005673577543348074, 0.007003595121204853, 0.006196566391736269, 0.0057073356583714485, 0.009078112430870533, 0.009670143947005272, 0.01785014197230339, 0.010230014100670815, 0.012074343860149384, 0.01841025985777378, 0.013498511165380478, 0.01554432138800621, 0.01643402688205242, 0.014670480974018574, 0.01402105763554573, 0.013053967617452145, 0.009886330924928188, 0.007721467409282923, 0.00174630805850029, 0.00208485359326005, 0.011514461599290371, 0.008777150884270668, 0.00519857881590724, 0.004536503925919533, 0.004512868821620941, 0.006709624081850052, 0.004872235003858805, 0.004064344335347414, 0.004150464199483395, 0.004383605904877186, 0.004612263757735491, 0.005236791446805, 0.005194412544369698, 0.0049428995698690414, 0.0044814045540988445, 0.004323561210185289, 0.004463978111743927, 0.005240947939455509, 0.005950119812041521, 0.007301781792193651, 0.00922483392059803, 0.008063718676567078, 0.007599055301398039, 0.007135025225579739, 0.006917673163115978, 0.006982714403420687, 0.0074474262073636055, 0.007500146050006151, 0.006740799639374018, 0.008596476167440414, 0.010557916946709156, 0.006966540589928627, 0.003808195237070322, 0.0014044094132259488, 0.0014547398313879967, 0.0014734298456460238, 0.0014365301467478275, 0.0030404538847506046, 0.0038048946298658848, 0.004395561758428812, 0.004066617228090763, 0.003885652869939804, 0.003754498902708292, 0.004455284681171179, 0.006675041280686855, 0.008338915184140205, 0.007294381968677044, 0.006442305166274309, 0.006481574848294258, 0.007434514816850424, 0.01097887009382248, 0.012328198179602623, 0.007612684741616249, 0.0023911336902529, 0.001362112001515925, 0.009151698090136051, 0.012135425582528114, 0.009160959161818027, 0.009320935234427452, 0.013277309946715832, 0.010174253955483437, 0.011347443796694279, 0.010820525698363781, 0.010719924233853817, 0.010036837309598923, 0.009346961043775082, 0.01012767106294632, 0.00862802378833294, 0.008944307453930378, 0.012059547938406467, 0.03336098790168762, 0.047858402132987976, 0.02846893109381199, 0.01894756406545639, 0.0172490943223238, 0.019559470936655998, 0.020328868180513382, 0.022240668535232544, 0.020183302462100983, 0.021290037781000137, 0.022434253245592117, 0.02537451684474945, 0.028930868953466415, 0.025720125064253807, 0.015249278396368027, 0.005322986748069525, 0.00712253712117672, 0.0045005520805716515, 0.014331148006021976, 0.012306946329772472, 0.02442859672009945, 0.044227469712495804, 0.0433524027466774, 0.01965738832950592, 0.012606510892510414, 0.014435159973800182, 0.018387960270047188, 0.018385976552963257, 0.005963537842035294, 0.002043448155745864, 0.013567280024290085, 0.017078682780265808, 0.05860885605216026, 0.034865349531173706, 0.02583407796919346, 0.032305385917425156, 0.03300871327519417, 0.024768147617578506, 0.01562829315662384, 0.005842492450028658, 0.008150981739163399, 0.007349861785769463, 0.007377891801297665, 0.008847212418913841, 0.011225638911128044, 0.00936773419380188, 0.007616272196173668, 0.005906319711357355, 0.005511151161044836, 0.0070404186844825745, 0.013392960652709007, 0.013045459054410458, 0.014458883553743362, 0.012452450580894947, 0.011682884767651558, 0.010896437801420689, 0.010741492733359337, 0.013292476534843445, 0.015102853998541832, 0.012432591989636421, 0.0119235934689641, 0.00326453591696918, 0.005544251762330532, 0.004650359973311424, 0.005509946495294571, 0.0052690147422254086, 0.0049285851418972015, 0.014750811271369457, 0.009316397830843925, 0.007948999293148518, 0.008549160324037075, 0.007041015662252903, 0.006247221492230892, 0.006664799526333809, 0.008135108277201653, 0.01113094761967659, 0.007359297014772892, 0.002275900449603796, 0.0016895717708393931, 0.001748574897646904, 0.007702281232923269, 0.007204847410321236, 0.006333319004625082, 0.005890006199479103, 0.005566522944718599, 0.005396557506173849, 0.005096519365906715, 0.006941240280866623, 0.005766426678746939, 0.009352469816803932, 0.020283378660678864, 0.01725396327674389, 0.0180638637393713, 0.014312878251075745, 0.011650853790342808, 0.011537021026015282, 0.012379453517496586, 0.01144399307668209, 0.01860637776553631, 0.037187010049819946, 0.01676994189620018, 0.00473819300532341, 0.00641643488779664, 0.0028213360346853733, 0.0019348871428519487, 0.0054220897145569324, 0.005554167088121176, 0.006483797449618578, 0.00447469437494874, 0.004846870433539152, 0.004920189268887043, 0.0069623300805687904, 0.010019160807132721, 0.01020912453532219, 0.008491157554090023, 0.0064124176278710365, 0.009947814047336578, 0.011833312921226025, 0.007590675260871649, 0.014499272219836712, 0.013169266283512115, 0.0028586408589035273, 0.0015448941849172115, 0.003217438468709588, 0.006632449571043253, 0.015120282769203186, 0.01596755161881447, 0.008372622542083263, 0.007082608062773943, 0.008541588671505451, 0.010935774073004723, 0.014609250240027905, 0.013640547171235085, 0.010814648121595383, 0.011960973031818867, 0.008826841600239277, 0.009418688714504242, 0.009134124964475632, 0.009569874033331871, 0.010979444719851017, 0.010821646079421043, 0.006232662592083216, 0.0014606171753257513, 0.0014275130815804005, 0.002186562167480588, 0.010510614141821861, 0.010920262895524502, 0.03460840880870819, 0.013143320567905903, 0.00972779281437397, 0.008067798800766468, 0.017566941678524017, 0.0054774959571659565, 0.002590905874967575, 0.00403206842020154, 0.006637998856604099, 0.004558994900435209, 0.0043070376850664616, 0.004263228736817837, 0.0035262787714600563, 0.0033400466199964285, 0.003855273360386491, 0.004864309914410114, 0.010252803564071655, 0.013097007758915424, 0.006761997006833553, 0.005731889512389898, 0.005843851715326309, 0.007364125922322273, 0.005768063012510538, 0.006064367946237326, 0.006470771506428719, 0.005965131334960461, 0.002677740529179573, 0.008223075419664383, 0.01660860888659954, 0.010964179411530495, 0.006669938564300537, 0.004896788392215967, 0.004986738786101341, 0.005978018045425415, 0.008490800857543945, 0.008989660069346428, 0.00960562564432621, 0.010667003691196442, 0.015424763783812523, 0.025686675682663918, 0.02212284505367279, 0.014971530996263027, 0.012553462758660316, 0.012267807498574257, 0.014147521927952766, 0.013971159234642982, 0.018432170152664185, 0.01648271270096302, 0.013370765373110771, 0.0095072565600276, 0.006607037503272295, 0.0018813975621014833, 0.0018067265627905726, 0.026147937402129173, 0.023875782266259193, 0.015520586632192135, 0.027034634724259377, 0.01626460812985897, 0.009353382512927055, 0.0093406792730093, 0.009641719050705433, 0.010621855035424232, 0.012886897660791874, 0.014613712206482887, 0.01426815614104271, 0.013609183020889759, 0.008665250614285469, 0.020101254805922508, 0.02338339388370514, 0.018989933654665947, 0.013806816190481186, 0.015709172934293747, 0.01505958754569292, 0.018192308023571968, 0.023173753172159195, 0.022892005741596222, 0.022757455706596375, 0.023263853043317795, 0.01927068643271923, 0.01083037257194519, 0.007006692700088024, 0.004663274623453617, 0.008609352633357048, 0.005662917625159025, 0.0029910190496593714, 0.006190173327922821, 0.006184006575495005, 0.005062283482402563, 0.006128500681370497, 0.007480164989829063, 0.008237550966441631, 0.015011897310614586, 0.012019066140055656, 0.011128791607916355, 0.011227973736822605, 0.012430296279489994, 0.012745551764965057, 0.013255182653665543, 0.012430788949131966, 0.00719188479706645, 0.0012237551854923368, 0.0012342820409685373, 0.0013154159532859921, 0.0013369456864893436, 0.001382143935188651, 0.0015706754056736827, 0.010180694051086903, 0.008235691115260124, 0.007010933943092823, 0.00816736277192831, 0.007435064762830734, 0.006467016879469156, 0.00626720953732729, 0.006340044550597668, 0.0072040315717458725, 0.007926677353680134, 0.00867685116827488, 0.009826021268963814, 0.00975272711366415, 0.010456669144332409, 0.01025176327675581, 0.009965422563254833, 0.010317409411072731, 0.010274780914187431, 0.010815447196364403, 0.010236348956823349, 0.0070782313123345375, 0.004045604728162289, 0.0037043828051537275, 0.0012006957549601793, 0.0016331919468939304, 0.003272160654887557, 0.003487598616629839, 0.004156057257205248, 0.004012205637991428, 0.004077678546309471, 0.0040070065297186375, 0.00362738617695868, 0.004209245089441538, 0.003850623033940792, 0.004176272079348564, 0.004471038933843374, 0.004680628888309002, 0.004553130362182856, 0.0064697591587901115, 0.007020301651209593, 0.005740948021411896, 0.006099856458604336, 0.006373930722475052, 0.00712435320019722, 0.008381014689803123, 0.0075921230018138885, 0.005964346695691347, 0.0011427982244640589, 0.0011549649061635137, 0.00729771563783288, 0.010716891847550869, 0.015154646709561348, 0.0033996370621025562, 0.00867836270481348, 0.004180979914963245, 0.00402875617146492, 0.004028143361210823, 0.004858557600528002, 0.008522795513272285, 0.006329574156552553, 0.006332111079245806, 0.0072612757794559, 0.00832894816994667, 0.01107086706906557, 0.010553241707384586, 0.007795389741659164, 0.0013056552270427346, 0.001177081954665482, 0.0012802707497030497, 0.0012776756193488836, 0.0032676381524652243, 0.004214967601001263, 0.004731845110654831, 0.005821497645229101, 0.005639015231281519, 0.006000911351293325, 0.0059871794655919075, 0.006706731393933296, 0.01158783957362175, 0.006736608687788248, 0.007281217258423567, 0.006972711533308029, 0.0112834507599473, 0.007246905937790871, 0.008029787801206112, 0.011250842362642288, 0.015950454398989677, 0.007173669524490833, 0.0011593865929171443, 0.0012592957355082035, 0.00640701362863183, 0.008115566335618496, 0.00758321350440383, 0.00516465911641717, 0.005594185553491116, 0.004944100975990295, 0.004815847147256136, 0.0056744534522295, 0.004803948570042849, 0.005406438373029232, 0.00897753145545721, 0.008329236879944801, 0.00905071571469307, 0.007655075751245022, 0.008655743673443794, 0.01019415631890297, 0.01225053146481514, 0.011352554894983768, 0.007550055161118507, 0.0014387763803824782, 0.0010959707433357835, 0.0010901651112362742, 0.0011300084879621863, 0.0019639916718006134, 0.005434649530798197, 0.005435118451714516, 0.003441832959651947, 0.003300062380731106, 0.0036338260397315025, 0.003672521561384201, 0.003243454033508897, 0.0031908887904137373, 0.0030841685365885496, 0.0035447711125016212, 0.005013831425458193, 0.0064033628441393375, 0.006655293516814709, 0.005890161730349064, 0.0058545200154185295, 0.005922003649175167, 0.006836558226495981, 0.009986774995923042, 0.0139581598341465, 0.006482897326350212, 0.0011126880999654531, 0.001122238696552813, 0.0011294459691271186, 0.0011902058031409979, 0.0010418881429359317, 0.0011178755667060614, 0.009681385941803455, 0.021027471870183945, 0.020869191735982895, 0.010366495698690414, 0.01202881895005703, 0.005356545560061932, 0.004765590652823448, 0.005523554980754852, 0.005599072203040123, 0.006227109115570784, 0.00599196320399642, 0.006418879609555006, 0.007578079588711262, 0.005506739020347595, 0.011001376435160637, 0.012507067993283272, 0.021131040528416634, 0.016694333404302597, 0.015492330305278301, 0.013023750856518745, 0.013603651896119118, 0.018867947161197662, 0.025780487805604935, 0.023851914331316948, 0.017934482544660568, 0.009115966968238354, 0.0013804985210299492, 0.0016933309379965067, 0.007300155702978373, 0.012654826045036316, 0.005517966113984585, 0.005411041434854269, 0.004863968584686518, 0.005274930503219366, 0.006567414849996567, 0.007564015686511993, 0.009389014914631844, 0.008419400081038475, 0.006559473928064108, 0.006129743531346321, 0.007642037235200405, 0.008194627240300179, 0.009518002159893513, 0.007964128628373146, 0.00952109694480896, 0.0011754999868571758, 0.0011679712915793061, 0.006561181508004665, 0.004294846206903458, 0.004286596551537514, 0.00490204943343997, 0.004633099772036076, 0.004728479310870171, 0.005382214207202196, 0.005910511594265699, 0.005290237721055746, 0.004999831318855286, 0.004309900104999542, 0.003924580756574869, 0.003991690464317799, 0.0038587211165577173, 0.006726386491209269, 0.007027009502053261, 0.007432512007653713, 0.007528706919401884, 0.007438838481903076, 0.006780206225812435, 0.007171310018748045, 0.006914524361491203, 0.006972918286919594, 0.00672068540006876, 0.007150139193981886, 0.00971241481602192, 0.014242546632885933, 0.01694498024880886, 0.01746942289173603, 0.00971839390695095, 0.006088397931307554, 0.001808872795663774, 0.0012140929466113448, 0.001098001142963767, 0.0013440269976854324, 0.004644614178687334, 0.0029783055651932955, 0.0011063392739742994, 0.009913555346429348, 0.01018520351499319, 0.006827440578490496, 0.00686733890324831, 0.005647007375955582, 0.006114442832767963, 0.006341871339827776, 0.006622090935707092, 0.006477195769548416, 0.006735385861247778, 0.00979594886302948, 0.009845899417996407, 0.010892448015511036, 0.010617212392389774, 0.010638805106282234, 0.012578418478369713, 0.014422363601624966, 0.01836331933736801, 0.025334712117910385, 0.025418920442461967, 0.018385574221611023, 0.0055694906041026115, 0.0011263270862400532, 0.0011720303446054459, 0.013918083161115646, 0.01758398860692978, 0.004418432246893644, 0.005684528965502977, 0.013432526029646397, 0.004850792698562145, 0.004047283437103033, 0.004157352726906538, 0.00544739468023181, 0.005745220929384232, 0.0057672462426126, 0.004974112380295992, 0.005256478674709797, 0.006692628376185894, 0.010688654147088528, 0.01010028924793005, 0.01090862788259983, 0.009346399456262589, 0.011900083161890507, 0.01925591193139553, 0.008010332472622395, 0.0017036524368450046, 0.001046900637447834, 0.012341401539742947, 0.011481604538857937, 0.007465663831681013, 0.005905147176235914, 0.005095011554658413, 0.009648039937019348, 0.01508895680308342, 0.009037869982421398, 0.009784144349396229, 0.010758787393569946, 0.012493697926402092, 0.004350272938609123, 0.0013196186628192663, 0.0021065755281597376, 0.006719899829477072, 0.005065031349658966, 0.0043932185508310795, 0.004392022266983986, 0.004800031427294016, 0.00440963264554739, 0.004129279404878616, 0.004647109191864729, 0.005633196793496609, 0.008884322829544544, 0.008366474881768227, 0.008044296875596046, 0.012538964860141277, 0.00752830458804965, 0.010954286903142929, 0.0067599439062178135, 0.002906210720539093, 0.0012147164670750499, 0.001078202505595982, 0.0011227335780858994, 0.00370705290697515, 0.0029920784290879965, 0.0032113187480717897, 0.0035918368957936764, 0.0052667041309177876, 0.005366517696529627, 0.005453175865113735, 0.004970496986061335, 0.0056432257406413555, 0.006178412586450577, 0.005255409982055426, 0.006277449894696474, 0.005329303443431854, 0.004906151443719864, 0.005231023766100407, 0.004892643541097641, 0.005868343636393547, 0.0060049304738640785, 0.0077797179110348225, 0.012191103771328926, 0.005402165465056896, 0.0009577799355611205, 0.0009748854790814221, 0.000999273033812642, 0.004335088189691305, 0.003260730765759945, 0.0032995676156133413, 0.004638548009097576, 0.005450730677694082, 0.007250857539474964, 0.007083202246576548, 0.007454180158674717, 0.004573130048811436, 0.004308131989091635, 0.008302130736410618, 0.012642409652471542, 0.008854652754962444, 0.009826458990573883, 0.00873145367950201, 0.007351245265454054, 0.007690561935305595, 0.009713017381727695, 0.0103662870824337, 0.01331310998648405, 0.014838864095509052, 0.014081987552344799, 0.011083289980888367, 0.0012042414164170623, 0.0010289011988788843, 0.0027697435580193996, 0.004054337274283171, 0.0044358051382005215, 0.006728875916451216, 0.008723423816263676, 0.008430413901805878, 0.0076321326196193695, 0.007199960760772228, 0.007535979151725769, 0.0068629528395831585, 0.007282125297933817, 0.006733259651809931, 0.01100342720746994, 0.009834373369812965, 0.006887241266667843, 0.007968636229634285, 0.011428327299654484, 0.008743396028876305, 0.014083163812756538, 0.010481471195816994, 0.001273835077881813, 0.0009358547395095229, 0.0009280453086830676, 0.0009867697954177856, 0.0009621270000934601, 0.003182499436661601, 0.0036578138824552298, 0.003859919961541891, 0.0038668110501021147, 0.0037260486278682947, 0.0035401242785155773, 0.003619546303525567, 0.005324178375303745, 0.008926387876272202, 0.006062827538698912, 0.005553920287638903, 0.006401377730071545, 0.006745149847120047, 0.007412871811538935, 0.007954079657793045, 0.008189033716917038, 0.0031993999145925045, 0.0009339764364995062, 0.0009215467143803835, 0.005297062918543816, 0.013854357413947582, 0.012805690988898277, 0.00882705021649599, 0.007896120660007, 0.008294639177620411, 0.008537253364920616, 0.00954953208565712, 0.013219835236668587, 0.016340408474206924, 0.020344989374279976, 0.02069464512169361, 0.016760731115937233, 0.013499666005373001, 0.017559263855218887, 0.01591392047703266, 0.011825098656117916, 0.012226997874677181, 0.004446396138519049, 0.002252491656690836, 0.007184021640568972, 0.007024033460766077, 0.006160825490951538, 0.005896747577935457, 0.006337855011224747, 0.00867539457976818, 0.007053082808852196, 0.006348671391606331, 0.00549320550635457, 0.005988023243844509, 0.007638969924300909, 0.008013896644115448, 0.007086344063282013, 0.006445321720093489, 0.009321670979261398, 0.0108433673158288, 0.009769972413778305, 0.011423846706748009, 0.013080190867185593, 0.007067558355629444, 0.0008786832913756371, 0.000935215619392693, 0.0008945257868617773, 0.000902388128452003, 0.0009364319848828018, 0.0033556511625647545, 0.0038116592913866043, 0.003740061307325959, 0.004028676077723503, 0.003979086875915527, 0.0031811620574444532, 0.003390455851331353, 0.00725210178643465, 0.0069514610804617405, 0.006890937685966492, 0.006803860422223806, 0.00583112146705389, 0.005618187598884106, 0.006202127784490585, 0.009076740592718124, 0.01209009625017643, 0.013530421070754528, 0.002907599089667201, 0.0008687188383191824, 0.0010337627027183771, 0.004054179880768061, 0.007663862779736519, 0.004448320716619492, 0.004467134829610586, 0.004649197217077017, 0.0034003849141299725, 0.0037107677198946476, 0.004879413638263941, 0.007392521947622299, 0.005827330518513918, 0.006342571694403887, 0.008725726045668125, 0.009042645804584026, 0.006459564436227083, 0.007439140230417252, 0.014819951727986336, 0.009761180728673935, 0.009935819543898106, 0.002042286330834031, 0.001397498301230371, 0.0011794917518272996, 0.0010086013935506344, 0.004021706525236368, 0.005961478687822819, 0.0036874485667794943, 0.008340100757777691, 0.006959091406315565, 0.003537688637152314, 0.00386838149279356, 0.004580752458423376, 0.008129961788654327, 0.008426460437476635, 0.007784310262650251, 0.007208928000181913, 0.011476634070277214, 0.007554749958217144, 0.004783518612384796, 0.005722460336983204, 0.008494577370584011, 0.01383558101952076, 0.006382280960679054, 0.0009006217587739229, 0.0008967484463937581, 0.0017058049561455846, 0.004605087451636791, 0.00456381356343627, 0.004472656641155481, 0.004365665838122368, 0.005141769535839558, 0.00440208101645112, 0.007644964382052422, 0.00651976466178894, 0.0059241047129035, 0.006147674284875393, 0.006150700617581606, 0.005594354588538408, 0.005487304180860519, 0.006384254898875952, 0.008282321505248547, 0.00885682925581932, 0.006713544949889183, 0.0011979903792962432, 0.0008778476621955633, 0.0023912768810987473, 0.004744956735521555, 0.008919484913349152, 0.01163248810917139, 0.014729199931025505, 0.013043614104390144, 0.008069205097854137, 0.009373247623443604, 0.007371329236775637, 0.0071160863153636456, 0.009836755692958832, 0.017137909308075905, 0.01736174337565899, 0.009747635573148727, 0.009259214624762535, 0.029486453160643578, 0.050694119185209274, 0.03083016909658909, 0.02968376874923706, 0.004594267345964909, 0.0011064226273447275, 0.0010419104946777225, 0.003645168850198388, 0.00898913387209177, 0.009660311974585056, 0.01133859995752573, 0.011750814504921436, 0.011174891144037247, 0.009205955080688, 0.008154226467013359, 0.01183395553380251, 0.012801067903637886, 0.011537991464138031, 0.011850317008793354, 0.012855730950832367, 0.02588369883596897, 0.015952492132782936, 0.015255821868777275, 0.015223361551761627, 0.010611320845782757, 0.0020929218735545874, 0.0010622072732076049, 0.0010590122547000647, 0.008410797454416752, 0.006658748257905245, 0.013397429138422012, 0.011299792677164078, 0.005383910611271858, 0.005210940260440111, 0.0063250004313886166, 0.005696733947843313, 0.005554595496505499, 0.0047342292964458466, 0.008787797763943672, 0.012504925020039082, 0.008552699349820614, 0.007640366442501545, 0.008057489059865475, 0.010441608726978302, 0.010468918830156326, 0.01763976737856865, 0.011422969400882721, 0.008136231452226639, 0.0030685686506330967, 0.0011796039761975408, 0.001112528843805194, 0.009771266020834446, 0.011244842782616615, 0.005923752207309008, 0.006502448581159115, 0.005145592615008354, 0.007848021574318409, 0.006493209861218929, 0.006056174635887146, 0.008251609280705452, 0.016270456835627556, 0.013137794099748135, 0.011285110376775265, 0.00945910532027483, 0.009487820789217949, 0.010171692818403244, 0.010618523694574833, 0.01213669404387474, 0.017076045274734497, 0.012983218766748905, 0.010889383964240551, 0.007941611111164093, 0.001173518830910325, 0.000948889646679163, 0.0009148070239461958, 0.005598301999270916, 0.008611245080828667, 0.008872240781784058, 0.011774993501603603, 0.010871621780097485, 0.009021528996527195, 0.010598876513540745, 0.00915299728512764, 0.008888037875294685, 0.010954097844660282, 0.009632849134504795, 0.006896556820720434, 0.007008715532720089, 0.010165851563215256, 0.01377847883850336, 0.015352942049503326, 0.008646681904792786, 0.0013449308462440968, 0.0008971747593022883, 0.001657495042309165, 0.008642886765301228, 0.008374813944101334, 0.013567788526415825, 0.005770583171397448, 0.009218933060765266, 0.008478539995849133, 0.010001890361309052, 0.007834300398826599, 0.008194459602236748, 0.009183079935610294, 0.008081506937742233, 0.008785998448729515, 0.011215574108064175, 0.009715549647808075, 0.009728352539241314, 0.009924933314323425, 0.011651311069726944, 0.00979618914425373, 0.01006039697676897, 0.01783197931945324, 0.02261989563703537, 0.018508849665522575, 0.008252586238086224, 0.0009487702045589685, 0.000776491651777178, 0.004531020764261484, 0.006219713483005762, 0.007146360352635384, 0.00861484557390213, 0.008174087852239609, 0.008364001289010048, 0.007113303989171982, 0.006062560249119997, 0.009193702600896358, 0.00665529677644372, 0.008625183254480362, 0.008039530366659164, 0.008286897093057632, 0.00816536694765091, 0.008030010387301445, 0.008934089913964272, 0.011581875383853912, 0.00712212361395359, 0.0025893659330904484, 0.0007796349818818271, 0.0007681535789743066, 0.0036320362705737352, 0.006918462458997965, 0.004915706813335419, 0.004625893663614988, 0.005310117732733488, 0.005062979646027088, 0.00446584727615118, 0.007749081123620272, 0.011986125260591507, 0.010439121164381504, 0.00936222169548273, 0.006628592498600483, 0.0066162701696157455, 0.007257910445332527, 0.009013076312839985, 0.013553858734667301, 0.013172460719943047, 0.010083752684295177, 0.004091332200914621, 0.0028792007360607386, 0.004683268256485462, 0.003147120587527752, 0.004497307352721691, 0.006515398155897856, 0.005651895888149738, 0.006708434317260981, 0.006927320268005133, 0.006243090610951185, 0.005846606567502022, 0.006999929901212454, 0.022407369688153267, 0.012838625349104404, 0.010094410739839077, 0.009031800553202629, 0.015365419909358025, 0.008353600278496742, 0.008782514370977879, 0.01805426925420761, 0.0162762850522995, 0.016718050464987755, 0.01006977166980505, 0.004054030403494835, 0.0008457470103166997, 0.0038630818016827106, 0.002886398695409298, 0.003493888769298792, 0.003931381739675999, 0.003841834608465433, 0.006013709586113691, 0.00482792966067791, 0.008103513158857822, 0.009409322403371334, 0.009032966569066048, 0.005425221286714077, 0.007782363332808018, 0.006485011428594589, 0.009209096431732178, 0.010281366296112537, 0.00867051724344492, 0.004025130067020655, 0.0007925502141006291, 0.0007628115126863122, 0.0007643597200512886, 0.013071260415017605, 0.006220925133675337, 0.004166595637798309, 0.0041537233628332615, 0.0037648777943104506, 0.004384950734674931, 0.004092320799827576, 0.004227057099342346, 0.010544506832957268, 0.010859961621463299, 0.012615268118679523, 0.014605050906538963, 0.014248726889491081, 0.01330341212451458, 0.011319886893033981, 0.01922575756907463, 0.005033544264733791, 0.0012482458259910345, 0.0011471658945083618, 0.005199631676077843, 0.008258117362856865, 0.005957047455012798, 0.0066643222235143185, 0.007146752439439297, 0.007316254545003176, 0.005057931877672672, 0.008855723775923252, 0.007701300084590912, 0.00925537385046482, 0.00812778901308775, 0.006944037973880768, 0.011633845046162605, 0.007261541672050953, 0.00735150370746851, 0.012470487505197525, 0.011640184558928013, 0.013568016700446606, 0.011804340407252312, 0.007997136563062668, 0.002187857637181878, 0.0017360063502565026, 0.0009846987668424845, 0.001320301671512425, 0.0035079556982964277, 0.009033838286995888, 0.011325136758387089, 0.010241534560918808, 0.008399817161262035, 0.007821504957973957, 0.01015947014093399, 0.01144513487815857, 0.012033602222800255, 0.017696429044008255, 0.017998984083533287, 0.018652085214853287, 0.016904229298233986, 0.009362692944705486, 0.0048034461215138435, 0.003609671024605632, 0.013255450874567032, 0.022987082600593567, 0.012499572709202766, 0.004703471902757883, 0.0038674899842590094, 0.003538740798830986, 0.005069096107035875, 0.004855216480791569, 0.004734537564218044, 0.005106825847178698, 0.005403812509030104, 0.012162518687546253, 0.03361162915825844, 0.03523453697562218, 0.0157301127910614, 0.013498404063284397, 0.01187098678201437, 0.05515884980559349, 0.06614907830953598, 0.044754114001989365, 0.0236003790050745, 0.01806003972887993, 0.015274918638169765, 0.008640115149319172, 0.01916462741792202, 0.022684279829263687, 0.012688561342656612, 0.013789269141852856, 0.004430505447089672, 0.021263927221298218, 0.010186300612986088, 0.00495949387550354, 0.005345135927200317, 0.005876544862985611, 0.006665190681815147, 0.006694226525723934, 0.008243605494499207, 0.012186639942228794, 0.0139376325532794, 0.01162515114992857, 0.014090921729803085, 0.012635750696063042, 0.0116586210206151, 0.012408805079758167, 0.01238200068473816, 0.008460624143481255, 0.002772812731564045, 0.0010817688889801502, 0.0009607815882191062, 0.013351303525269032, 0.018207306042313576, 0.020211664959788322, 0.01892552524805069, 0.013925490900874138, 0.007619699463248253, 0.011062854900956154, 0.007791370153427124, 0.014526247046887875, 0.013373957015573978, 0.00818277895450592, 0.008032022975385189, 0.008784232661128044, 0.010241538286209106, 0.011304163374006748, 0.012837214395403862, 0.009284722618758678, 0.008041158318519592, 0.010757723823189735, 0.010687327943742275, 0.008039209060370922, 0.001517341355793178, 0.0013467691605910659, 0.004110823385417461, 0.0040755788795650005, 0.004272459074854851, 0.005254815332591534, 0.005448032170534134, 0.01026745792478323, 0.010847832076251507, 0.01006955374032259, 0.009729894809424877, 0.010749991051852703, 0.009606543928384781, 0.011858952231705189, 0.00873552169650793, 0.011114930734038353, 0.010170196183025837, 0.012769515626132488, 0.016171637922525406, 0.013917317613959312, 0.005120238289237022, 0.002183863427489996, 0.0015026065520942211, 0.0008623251924291253, 0.0028812449891120195, 0.003274880815297365, 0.0061406721360981464, 0.004646779969334602, 0.004403769038617611, 0.0047792973928153515, 0.0050106714479625225, 0.006119946483522654, 0.006326134316623211, 0.0058692884631454945, 0.004936073441058397, 0.005207871086895466, 0.007198262959718704, 0.01553327776491642, 0.03781135752797127, 0.04256320372223854, 0.025537565350532532, 0.008229418657720089, 0.008322144858539104, 0.010687998495995998, 0.013648966327309608, 0.012763157486915588, 0.007212180644273758, 0.00191587139852345, 0.003511670045554638, 0.0019778392743319273, 0.003361825132742524, 0.0054464624263346195, 0.007369033060967922, 0.00845540314912796, 0.018193306401371956, 0.01935514062643051, 0.014296585693955421, 0.011466361582279205, 0.013906314969062805, 0.022396832704544067, 0.02224937453866005, 0.02060358226299286, 0.017337530851364136, 0.012607799842953682, 0.010500012896955013, 0.009561363607645035, 0.01207741815596819, 0.02222965657711029, 0.027061130851507187, 0.02241384983062744, 0.01517488993704319, 0.003739418461918831, 0.004358140751719475, 0.0035809348337352276, 0.007597746793180704, 0.007876276038587093, 0.007680324837565422, 0.008384446613490582, 0.008168330416083336, 0.012738381512463093, 0.02598254755139351, 0.013029931113123894, 0.011242358013987541, 0.014749906957149506, 0.021845776587724686, 0.0039960118010640144, 0.0008950665360316634, 0.000893354881554842, 0.0009087294456548989, 0.003345463890582323, 0.003229102585464716, 0.003325283993035555, 0.003535897471010685, 0.00387124577537179, 0.0037587492261081934, 0.0038720062002539635, 0.004088348709046841, 0.013025251217186451, 0.008442895486950874, 0.008516103029251099, 0.007990398444235325, 0.009067567065358162, 0.014282687567174435, 0.013094554655253887, 0.02340725064277649, 0.003983976785093546, 0.0007633273489773273, 0.0007751217926852405, 0.0033249640837311745, 0.005309039261192083, 0.01020873710513115, 0.016255799680948257, 0.012017578817903996, 0.009817605838179588, 0.008713110350072384, 0.007221125066280365, 0.00659604137763381, 0.009713314473628998, 0.013810382224619389, 0.014723883010447025, 0.013011208735406399, 0.010944565758109093, 0.012468731962144375, 0.014642564579844475, 0.015082631260156631, 0.013102858327329159, 0.01107815746217966, 0.0036650279071182013, 0.0008855766500346363, 0.000738069589715451, 0.0007090420695021749, 0.008381564170122147, 0.013309713453054428, 0.009074369445443153, 0.00665508396923542, 0.014252007938921452, 0.00736261997371912, 0.006274242419749498, 0.006352855358272791, 0.007500072941184044, 0.00597652792930603, 0.006598343141376972, 0.007174313068389893, 0.0066654272377491, 0.007406509015709162, 0.007506813388317823, 0.007863781414926052, 0.014134841971099377, 0.020070644095540047, 0.018870476633310318, 0.014643173664808273, 0.01337550487369299, 0.014486078172922134, 0.010008920915424824, 0.009679651819169521, 0.010097751393914223, 0.010558025911450386, 0.009328410029411316, 0.010981902480125427, 0.014640993438661098, 0.01524732168763876, 0.014456589706242085, 0.0031642881222069263, 0.004983646795153618, 0.003711181925609708, 0.002603676402941346, 0.0011978131951764226, 0.0007625402649864554]\n",
            "The data type of the prediction is :  <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "total_loss=0\n",
        "\n",
        "#Training\n",
        "\n",
        "#epoch -> entire run of a CNN through an entire training dataset.\n",
        "#enumeration of a data loader-> passing batches of data to train the model, backpropogate error and optimise weights\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  #setting the model mode to train\n",
        "  UNET_Model.train()\n",
        "\n",
        "  images_list=[]\n",
        "  masks_list=[]\n",
        "  images_path_list=[]\n",
        "  masks_path_list=[]\n",
        "  predictions_list=[]\n",
        "  target_maps_list=[]\n",
        "\n",
        "  #looping through batches of data made by the training DataLoader.\n",
        "  for (batch_index,(image,mask,imagePath,maskPath,target_map)) in tqdm.tqdm(enumerate(train_loader),total=len(train_loader)):\n",
        "    \n",
        "    #switching the data over to the GPU\n",
        "    image=image.to(device)\n",
        "    #somehow target_map becomes a tensor from a np array. values still remain the same (0,1,2)\n",
        "    #shape of target-> batch, 1(channel), width, height\n",
        "\n",
        "    target_map= torch.squeeze(target_map) #removing the 1 channel this is because CELoss expects form->[N, H, W]\n",
        "    #print(\"target_map dimension\",target_map.shape)\n",
        "    target_map=target_map.to(dtype=torch.long)\n",
        "    target_map=target_map.to(device) \n",
        "\n",
        "    if i==num_epochs-1:\n",
        "      #adding images and masks in this list to batch\n",
        "      images_list.append(image)\n",
        "      masks_list.append(mask)\n",
        "      images_path_list.append(imagePath)\n",
        "      masks_path_list.append(maskPath)\n",
        "      target_maps_list.append(target_map)\n",
        "\n",
        "    predictions=UNET_Model(image)\n",
        "\n",
        "    # #moving predictions to cpu and appending it to list, to see if it prevents CUDA out of memory.\n",
        "    predictions_list.append(predictions.cpu())\n",
        "\n",
        "    #predictions_list.append(predictions)\n",
        "\n",
        "    #print(\"The data type of the prediction is : \",type(predictions))\n",
        "\n",
        "    #Calculating loss\n",
        "    \n",
        "    loss=loss_function(predictions,target_map)\n",
        "    training_loss_list.append(loss.item())\n",
        "    #total_loss+=loss.item()\n",
        "\n",
        "    #zeroing out accumulated gradients as weights have already been modified according to them during the previous run.\n",
        "    optimizer_function.zero_grad()\n",
        "\n",
        "    #Back propogation:\n",
        "    loss.backward()\n",
        "\n",
        "    #updating weights\n",
        "    optimizer_function.step()\n",
        "\n",
        "\n",
        "print(\"Ended training phase\")\n",
        "print(\"Training losses are as follows: \",training_loss_list)\n",
        "\n",
        "##NOTE: Images are represented during training in the format: [batchsize,channels,height,width]\n",
        "\n",
        "#displaying the predicted mask and the actual mask\n",
        "print(\"The data type of the prediction is : \",type(predictions))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzhPQjGJinWy"
      },
      "outputs": [],
      "source": [
        "#array[0][:][:][:]\n",
        "print(\"Predictions stored: \",len(predictions_list))\n",
        "print(\"Predictions(from model) shape:\",predictions.shape)\n",
        "\n",
        "print(\"Images stored\",len(images_list))\n",
        "print(\"Masks stored\",len(masks_list))\n",
        "print(\"Target maps stored\", len(target_maps_list))\n",
        "\n",
        "print(\"Image paths stored\",len(images_path_list))\n",
        "print(\"Mask paths stored\",len(masks_path_list))\n",
        "\n",
        "#getting a certain index of predictions,images and masks.\n",
        "list_index=1060\n",
        "image=images_list[list_index]\n",
        "mask= masks_list[list_index]\n",
        "predictions=predictions_list[list_index]\n",
        "target_map=target_maps_list[list_index]\n",
        "\n",
        "#to convert tensor to numpy array to plot, switch it from gpu to cpu\n",
        "mask=mask.cpu()\n",
        "predictions=predictions.cpu()\n",
        "image=image.cpu()\n",
        "\n",
        "print(\"Shape of the Image from list : \", image.shape)\n",
        "print(\"Shape of the expected mask from list: \", mask.shape)\n",
        "print(\"Shape of the predictions from list: \", predictions.shape)\n",
        "print(\"Shape of the target_maps from list: \",target_map.shape)\n",
        "\n",
        "print(\"Image used: \",images_path_list[list_index])\n",
        "print(\"Mask used: \",masks_path_list[list_index])\n",
        "\n",
        "\n",
        "batch=batch_size-1\n",
        "\n",
        "#taking a single image from the batch of images, \n",
        "#permuting it to display it and then displaying the input image using pyplot's imshow function.\n",
        "print(\"Input image\")\n",
        "image=image[batch][:][:][:]\n",
        "image=image.permute(1,2,0)\n",
        "plt.imshow(image.detach().numpy())\n",
        "plt.show()\n",
        "\n",
        "#reading in mask 1, from the batch of 32. \n",
        "#Also permuting it, so shape becomes [height,width,channel]\n",
        "print(\"Expected mask\")\n",
        "mask=mask[batch][:][:][:]\n",
        "mask=mask.permute(1,2,0)\n",
        "plt.imshow(mask.detach().numpy())\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Ground truth target mask passed into loss func:\")\n",
        "target_map=target_map.cpu()\n",
        "visualiser_colab(target_map[batch][:][:])\n",
        "print(\"The Model output mask\")\n",
        "\n",
        "print(\"Prediction type from list : \",type(predictions))\n",
        "\n",
        "#reading in prediction 1, from the batch of 32\n",
        "#also permuting it so shape becomes [height,width,channel]\n",
        "predictions=predictions[batch][:][:][:]\n",
        "print(\"predictions shape before being displayed: \",predictions.shape)\n",
        "predictions=predictions.permute(1,2,0) #shape becomes 128,128,3\n",
        "print(\"Predictions shape after permuting it:\",predictions.shape)\n",
        "# predictions=transf(predictions)\n",
        "visualiser_colab(predictions.detach().numpy())\n",
        "\n",
        "\n",
        "\n",
        "# #printing out the prediction as a numpy array with 0,1 intensity.\n",
        "# imageDisp=np.clip(predictions.detach().numpy(), 0, 1)\n",
        "# plt.imshow(imageDisp)\n",
        "# plt.show()\n",
        "\n",
        "# #printing out the prediction as a numpy array, and trying to remove the clipping warning\n",
        "# imageDisp=predictions.detach().numpy()\n",
        "# plt.imshow((imageDisp* 255).astype(np.uint8))\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fSamggw9rS0A"
      },
      "outputs": [],
      "source": [
        "#function to calculate dice score\n",
        "\n",
        "\n",
        "\n",
        "#calculating dice score for predictions stored in the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5FI_IKUwxoBL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HXaq4TNUfbZj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "N-aprHfo9qUM"
      },
      "outputs": [],
      "source": [
        "#SAVING THE MODEL\n",
        "path=\"/content/drive/MyDrive/FYP-Aortic_Dissection_Segmentation/saved_model-fulldataset-4epoch\"\n",
        "torch.save(UNET_Model,path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "practiceInitial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "f49d0fc0e1a62c2e2d90b2c478c493e6e1789ab5d4aba8233aecb17a3c2190e7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}